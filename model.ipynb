{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.cluster import DBSCAN, KMeans\n",
    "from sklearn.neighbors import KernelDensity\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, OneHotEncoder\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.neighbors import KernelDensity\n",
    "from scipy.signal import argrelextrema\n",
    "import kmeans1d\n",
    "'''\n",
    "kmeans1d\n",
    "\n",
    "A Python library with an implementation of k-means clustering on 1D data, based on the algorithm in (Xiaolin 1991), as presented in section 2.2 of (Gronlund et al., 2017).\n",
    "\n",
    "Globally optimal k-means clustering is NP-hard for multi-dimensional data. Lloyd's algorithm is a popular approach for finding a locally optimal solution. For 1-dimensional data, there are polynomial time algorithms. The algorithm implemented here is a O(kn + n log n) dynamic programming algorithm for finding the globally optimal k clusters for n 1D data points.\n",
    "\n",
    "The code is written in C++, and wrapped with Python.\n",
    "'''\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shape (381109, 11)\n",
    "data = pd.read_csv('datasets/d1.csv')\n",
    "data = data.drop(['id'], axis=1)\n",
    "\n",
    "# data_2 = pd.read_csv('datasets/d2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Gender                    2\n",
       "Age                      54\n",
       "Driving_License           1\n",
       "Region_Code              42\n",
       "Previously_Insured        2\n",
       "Vehicle_Age               3\n",
       "Vehicle_Damage            2\n",
       "Annual_Premium          166\n",
       "Policy_Sales_Channel     23\n",
       "Vintage                 152\n",
       "Response                  2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "freq = pd.DataFrame({'Response':['0', '1'], 'nostoextract':[46710, 46710], })\n",
    "def bootstrap(data, freq):\n",
    "    freq = freq.set_index('Response')\n",
    "\n",
    "    # This function will be applied on each group of instances of the same\n",
    "    # class in `data`.\n",
    "    def sampleClass(classgroup):\n",
    "        cls = classgroup['Response'].iloc[0]\n",
    "        nDesired = freq.nostoextract[cls]\n",
    "        nRows = len(classgroup)\n",
    "\n",
    "        nSamples = min(nRows, nDesired)\n",
    "        return classgroup.sample(nSamples)\n",
    "\n",
    "    samples = data.groupby('Response').apply(sampleClass)\n",
    "\n",
    "    # If you want a new index with ascending values\n",
    "    # samples.index = range(len(samples))\n",
    "\n",
    "    # If you want an index which is equal to the row in `data` where the sample\n",
    "    # came from\n",
    "    samples.index = samples.index.get_level_values(1)\n",
    "\n",
    "    # If you don't change it then you'll have a multiindex with level 0\n",
    "    # being the class and level 1 being the row in `data` where\n",
    "    # the sample came from.\n",
    "\n",
    "    return samples\n",
    "\n",
    "data = bootstrap(data,freq)\n",
    "df = data.copy()\n",
    "df = df.sample(200, random_state=24) # 24\n",
    "df['Response'].value_counts().plot(kind='bar') \n",
    "df.nunique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 3.38 s\n",
      "Wall time: 830 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Driving_License</th>\n",
       "      <th>Region_Code</th>\n",
       "      <th>Previously_Insured</th>\n",
       "      <th>Vehicle_Age</th>\n",
       "      <th>Vehicle_Damage</th>\n",
       "      <th>Annual_Premium</th>\n",
       "      <th>Policy_Sales_Channel</th>\n",
       "      <th>Vintage</th>\n",
       "      <th>Response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>140358</th>\n",
       "      <td>Female</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>46.0</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt; 1 Year</td>\n",
       "      <td>No</td>\n",
       "      <td>2</td>\n",
       "      <td>152.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145987</th>\n",
       "      <td>Female</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt; 1 Year</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153353</th>\n",
       "      <td>Female</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1-2 Year</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15594</th>\n",
       "      <td>Female</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>&gt; 2 Years</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218355</th>\n",
       "      <td>Female</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt; 1 Year</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29071</th>\n",
       "      <td>Male</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>&gt; 2 Years</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2</td>\n",
       "      <td>124.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316521</th>\n",
       "      <td>Female</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>&gt; 2 Years</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2</td>\n",
       "      <td>26.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5548</th>\n",
       "      <td>Female</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt; 1 Year</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48321</th>\n",
       "      <td>Female</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1-2 Year</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5965</th>\n",
       "      <td>Female</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>46.0</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt; 1 Year</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Gender  Age  Driving_License  Region_Code  Previously_Insured  \\\n",
       "140358  Female    1                1         46.0                   1   \n",
       "145987  Female    1                1         25.0                   0   \n",
       "153353  Female    4                1         36.0                   0   \n",
       "15594   Female    3                1         28.0                   0   \n",
       "218355  Female    1                1         10.0                   1   \n",
       "...        ...  ...              ...          ...                 ...   \n",
       "29071     Male    2                1         28.0                   0   \n",
       "316521  Female    7                1         28.0                   0   \n",
       "5548    Female    1                1         18.0                   0   \n",
       "48321   Female    3                1         28.0                   0   \n",
       "5965    Female    4                1         46.0                   0   \n",
       "\n",
       "       Vehicle_Age Vehicle_Damage  Annual_Premium  Policy_Sales_Channel  \\\n",
       "140358    < 1 Year             No               2                 152.0   \n",
       "145987    < 1 Year            Yes               0                 152.0   \n",
       "153353    1-2 Year            Yes               2                  26.0   \n",
       "15594    > 2 Years            Yes               2                   3.0   \n",
       "218355    < 1 Year             No               0                 152.0   \n",
       "...            ...            ...             ...                   ...   \n",
       "29071    > 2 Years            Yes               2                 124.0   \n",
       "316521   > 2 Years            Yes               2                  26.0   \n",
       "5548      < 1 Year            Yes               0                 160.0   \n",
       "48321     1-2 Year            Yes               0                 156.0   \n",
       "5965      < 1 Year             No               0                 152.0   \n",
       "\n",
       "        Vintage  Response  \n",
       "140358        2         0  \n",
       "145987        1         0  \n",
       "153353        0         1  \n",
       "15594         0         1  \n",
       "218355        0         0  \n",
       "...         ...       ...  \n",
       "29071         0         1  \n",
       "316521        2         0  \n",
       "5548          1         0  \n",
       "48321         0         0  \n",
       "5965          2         0  \n",
       "\n",
       "[200 rows x 11 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "\n",
    "class Error(Exception):\n",
    "    \"\"\"Base class for other exceptions\"\"\"\n",
    "    pass\n",
    "\n",
    "\n",
    "class NotMatchResult(Error):\n",
    "    \"\"\"Raised when the input value is too small\"\"\"\n",
    "    pass\n",
    "\n",
    "\n",
    "class DRST:\n",
    "    '''\n",
    "        An Efficient Discretization Algorithm Using Rough Set Theory\n",
    "\n",
    "        ...\n",
    "\n",
    "        Attributes\n",
    "        ----------\n",
    "        checker_type : str='topN'\n",
    "            Type of the checker of data to determind wether data column is Continous or Discrete\n",
    "\n",
    "        Methods\n",
    "        -------\n",
    "        fit(x: DataFrame, continous_columns: list)\n",
    "\n",
    "        Note\n",
    "        -------\n",
    "\n",
    "        Example\n",
    "        -------\n",
    "\n",
    "\n",
    "    '''\n",
    "\n",
    "    def __init__(\n",
    "        self, \n",
    "        checker_type: str = 'topN', \n",
    "        comb_max_depth: int = None\n",
    "        ):\n",
    "        # Primary Data Information\n",
    "        self.data = None\n",
    "        self.columns = None\n",
    "        self.continuous_columns = None\n",
    "        self.discrete_columns = None\n",
    "        self.scaled_data = None\n",
    "\n",
    "        # Secondary Data infromation\n",
    "        self.data_after_INI = None\n",
    "        self.silhouette_scores = None\n",
    "\n",
    "        # check_discrete\n",
    "        self.dis_check_threshold = 0.5\n",
    "        self.dis_checker = checker_type  # ratio\n",
    "        self.checker_top_n = 10  # defult number of top N for topN checker\n",
    "\n",
    "        # Config Tools\n",
    "        self.scaler = StandardScaler()\n",
    "        self.natural_interval_model = 'kmeans'\n",
    "        self.NIM_message = 'Model for initiat the natural intervals cannot be blank'\n",
    "        self.comb_max_depth = comb_max_depth\n",
    "        self.all_combinations = None\n",
    "\n",
    "    def fit(\n",
    "            self,\n",
    "            x: pd.DataFrame,\n",
    "            continous_columns: list = [],\n",
    "            natural_interval_model: str = 'kmeans'\n",
    "    ):\n",
    "        \"\"\"Discretization using Rough Sets Theory (RST).\n",
    "\n",
    "        Fit `x` to an efficient intervals using the concept of RST \n",
    "        * asd\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : DataFrame\n",
    "            Full DataFrame (default is None)\n",
    "\n",
    "        continous_columns : list\n",
    "            Determind names of column(s) in the DataFarme as Continuous data. If `None` a function _check_continuous triger to determind names of column(s).\n",
    "\n",
    "        Raises\n",
    "        ------\n",
    "        NotMatchResult\n",
    "            If continous_columns `~None` model check the input with the checker determation if didn't match the result\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        # Reduct Data Intervals phase: Pre-process of discretization, intiate classification\n",
    "        # Pre-process of discretization\n",
    "        self.data = x\n",
    "        self.columns = self.data.columns\n",
    "        self.continuous_columns = continous_columns if continous_columns else self._check_continuous()\n",
    "        self.discrete_columns = list(set(self.columns).difference(self.continuous_columns))\n",
    "        \n",
    "        self.scaled_data = self._scaling_continuous()\n",
    "        self.silhouette_scores = self._get_silhouette_score()\n",
    "        # print(self.silhouette_scores)\n",
    "\n",
    "        # Intiate classification\n",
    "        self.data_after_INI = getattr(self, '_%s_model' % natural_interval_model, lambda: self.NIM_message)()\n",
    "        # print(self.data_after_INI.nunique())\n",
    "        self.data_after_INI.sort_values(['Annual_Premium']).to_csv('%s_model.csv' % natural_interval_model)\n",
    "        self.all_combinations = self.get_combinations()\n",
    "\n",
    "        data = self.data.copy()\n",
    "        data[self.continuous_columns] = self.data_after_INI.to_numpy()\n",
    "        return data\n",
    "    \n",
    "    def _dbscan_model(self):\n",
    "        result = {}\n",
    "        for att in self.continuous_columns:\n",
    "            clustering = DBSCAN(eps=1, min_samples=5).fit(\n",
    "                self._np_array_reshaped(self.data[att])\n",
    "            )\n",
    "            result[att] = clustering.labels_\n",
    "        return pd.DataFrame(result)\n",
    "\n",
    "    def _kmeans_model(self):\n",
    "        result = {}\n",
    "        for att in self.continuous_columns:\n",
    "            clustering = KMeans(n_clusters=self.silhouette_scores[att]).fit(\n",
    "                self._np_array_reshaped(self.scaled_data[att])\n",
    "            )\n",
    "            result[att] = clustering.labels_\n",
    "        return pd.DataFrame(result)\n",
    "\n",
    "    def _np_array_reshaped(self, data, reshape=(-1, 1)):\n",
    "        return np.array(data.tolist()).reshape(reshape[0], reshape[1])\n",
    "\n",
    "    def _check_continuous(self, continous_columns: list = []):\n",
    "        top_n = self.checker_top_n\n",
    "        likely = []\n",
    "\n",
    "        # check if attribute is continuous or discrete dataframe\n",
    "        for var in self.data.columns:\n",
    "            if self.dis_checker == 'topN':\n",
    "                # Check if the top n unique values account for more than a certain proportion of all values\n",
    "                if 1.*self.data[var].value_counts(normalize=True).head(top_n).sum() < 0.5:\n",
    "                    likely.append(var)\n",
    "            elif self.dis_checker == 'ratio':\n",
    "                # Find the ratio of number of unique values to the total number of unique values. Something like the following\n",
    "                if 1.*self.data[var].nunique()/self.data[var].count() > 0.5:\n",
    "                    likely.append(var)\n",
    "\n",
    "        common_names = ['id']\n",
    "        \n",
    "        return [x for x in likely if x.lower() not in common_names]\n",
    "\n",
    "    def _scaling_continuous(self):\n",
    "        \n",
    "        data_cluster = self.data[self.continuous_columns].copy()\n",
    "        scaled_columns = self.scaler.fit_transform(data_cluster)\n",
    "        self.scaled_data = self.data.copy()\n",
    "        self.scaled_data[self.continuous_columns] = scaled_columns\n",
    "\n",
    "        return self.scaled_data\n",
    "        \n",
    "    def _get_silhouette_score(self):\n",
    "        scores = {}\n",
    "        for att in self.continuous_columns:\n",
    "            temp_score = []\n",
    "            scores[att] = 3\n",
    "            for n_clusters in range(3,9):\n",
    "                # Initialize the clusterer with n_clusters value and a random generator\n",
    "                # seed of 10 for reproducibility.\n",
    "                clusterer = KMeans(n_clusters=n_clusters, random_state=10)\n",
    "                cluster_labels = clusterer.fit_predict(self._np_array_reshaped(self.scaled_data[att]))\n",
    "\n",
    "                # The silhouette_score gives the average value for all the samples.\n",
    "                # This gives a perspective into the density and separation of the formed\n",
    "                # clusters\n",
    "                silhouette_avg = silhouette_score(self._np_array_reshaped(self.scaled_data[att]), cluster_labels)\n",
    "                temp_score.append(silhouette_avg)\n",
    "            scores[att] = temp_score.index(max(temp_score)) + 3\n",
    "        return scores\n",
    "    \n",
    "    def get_combinations(self, comb_max_depth: int = None):\n",
    "        if not comb_max_depth:\n",
    "            comb_max_depth = self.comb_max_depth\n",
    "        combX = []\n",
    "        for idx, _ in enumerate(self.discrete_columns):\n",
    "            if comb_max_depth and comb_max_depth == idx:\n",
    "                break\n",
    "            combX.extend(list(combinations(self.discrete_columns, idx + 1)))\n",
    "\n",
    "        return sorted(combX, key=len)\n",
    "\n",
    "drst = DRST()\n",
    "# drst.fit(data_1, natural_interval_model='kmeans', continous_columns=['months_as_customer','total_claim_amount'])\n",
    "# drst.fit(data_1, natural_interval_model='kmeans')\n",
    "\n",
    "drst_fit = drst.fit(df)\n",
    "drst_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0c34a26dce7bb7449e42c35f5e9b82d8f7c9f77a71ba73bf71e175f0017805aa"
  },
  "kernelspec": {
   "display_name": "Python 3.10.3 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
