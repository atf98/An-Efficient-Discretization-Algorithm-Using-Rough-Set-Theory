{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tooldev import RST\n",
    "from tooldev.sample import bootstrap\n",
    "\n",
    "from itertools import combinations\n",
    "\n",
    "import re\n",
    "import random\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import collections\n",
    "\n",
    "from sklearn.cluster import DBSCAN, KMeans\n",
    "from sklearn.neighbors import KernelDensity\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, OneHotEncoder\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.neighbors import KernelDensity\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = pd.read_csv('datasets/d1.csv') # Orignal Dataset shape (381109, 11)\n",
    "# data = data.drop(['id'], axis=1)\n",
    "\n",
    "data = pd.read_csv('datasets/d1_bootstraped.csv')\n",
    "\n",
    "# data_2 = pd.read_csv('datasets/d2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment for creating a new sample of the datasets with bootstrap\n",
    "# freq = pd.DataFrame({'Response':['0', '1'], 'nostoextract':[46710, 46710], })\n",
    "# data = bootstrap(data,freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "\n",
    "class Error(Exception):\n",
    "    \"\"\"Base class for other exceptions\"\"\"\n",
    "    pass\n",
    "\n",
    "\n",
    "class NotMatchResult(Error):\n",
    "    \"\"\"Raised when the input value is too small\"\"\"\n",
    "    pass\n",
    "\n",
    "\n",
    "class DRST:\n",
    "    '''\n",
    "        An Efficient Discretization Algorithm Using Rough Set Theory\n",
    "\n",
    "        ...\n",
    "\n",
    "        Attributes\n",
    "        ----------\n",
    "        checker_type : str='topN'\n",
    "            Type of the checker of data to determind wether data column is Continous or Discrete\n",
    "\n",
    "        Methods\n",
    "        -------\n",
    "        fit(x: DataFrame, continous_columns: list)\n",
    "\n",
    "        Note\n",
    "        -------\n",
    "\n",
    "        Example\n",
    "        -------\n",
    "\n",
    "\n",
    "    '''\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        checker_type: str = 'topN',\n",
    "        comb_max_depth: int = None,\n",
    "        decision_column_name: str = 'class',\n",
    "    ):\n",
    "\n",
    "        # Primary Data Information\n",
    "        self.data = None\n",
    "        self.prepared_data = None\n",
    "        self.columns = None\n",
    "        self.continuous_columns = None\n",
    "        self.discrete_columns = None\n",
    "        self.scaled_data = None\n",
    "        self.decision_column_name = decision_column_name\n",
    "\n",
    "        # Secondary Data infromation\n",
    "        self.data_after_INI = None\n",
    "        self.silhouette_scores = None\n",
    "        self.lower_edge_value = {}\n",
    "        self.upper_edge_value = {}\n",
    "        self.outer_edge_value = {}\n",
    "        \n",
    "        # check_discrete\n",
    "        self.dis_check_threshold = 0.5\n",
    "        self.dis_checker = checker_type  # ratio\n",
    "        self.checker_top_n = 10  # defult number of top N for topN checker\n",
    "\n",
    "        # Config Tools\n",
    "        self.rst = None\n",
    "        self.encoder = LabelEncoder()\n",
    "        self.encoder_dict = dict()\n",
    "        self.scaler = StandardScaler()\n",
    "        self.natural_interval_model = 'kmeans'\n",
    "        self.NIM_message = 'Model for initiat the natural intervals cannot be blank'\n",
    "        self.comb_max_depth = comb_max_depth\n",
    "        self.all_combinations = None\n",
    "\n",
    "    def fit(\n",
    "            self,\n",
    "            x: pd.DataFrame,\n",
    "            continous_columns: list = [],\n",
    "            natural_interval_model: str = 'kmeans'\n",
    "    ):\n",
    "        \"\"\"Discretization using Rough Sets Theory (RST).\n",
    "\n",
    "        Fit `x` to an efficient intervals using the concept of RST \n",
    "        * asd\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : DataFrame\n",
    "            Full DataFrame (default is None)\n",
    "\n",
    "        continous_columns : list\n",
    "            Determind names of column(s) in the DataFarme as Continuous data. If `None` a function _check_continuous triger to determind names of column(s).\n",
    "\n",
    "        Raises\n",
    "        ------\n",
    "        NotMatchResult\n",
    "            If continous_columns `~None` model check the input with the checker determation if didn't match the result\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        # Reduct Data Intervals phase: Pre-process of discretization, intiate classification\n",
    "        # Pre-process of discretization\n",
    "        self.data = x\n",
    "        self.columns = self.data.columns\n",
    "        self.continuous_columns = continous_columns if continous_columns else self._check_continuous()\n",
    "        self.discrete_columns = list(set(self.columns).difference(self.continuous_columns))\n",
    "        self.discrete_columns.remove(self.decision_column_name)\n",
    "        self.scaled_data = self._scaling_continuous()\n",
    "        self.silhouette_scores = self._get_silhouette_score()\n",
    "\n",
    "        # Intiate classification\n",
    "        self.data_after_INI = getattr(self, '_%s_model' % natural_interval_model, lambda: self.NIM_message)()\n",
    "        self.all_combinations = self.get_combinations()\n",
    "        print(self.data_after_INI.nunique())\n",
    "\n",
    "        data = self.data.copy()  # local data vriable to save change in\n",
    "        data = self._labeling_discrete(data)\n",
    "        self.data_after_INI.columns = map((lambda x: x + '_AFTER'), self.data_after_INI.columns)\n",
    "\n",
    "        data = pd.concat([\n",
    "            data.reset_index(drop=True),\n",
    "            self.data_after_INI.reset_index(drop=True)\n",
    "        ], axis=1)\n",
    "\n",
    "        dependency_original_dict = {}\n",
    "        dependency_dict = {}\n",
    "\n",
    "        # Duplicate Continuous columns\n",
    "        for continuous_att in self.continuous_columns:\n",
    "            att_AFTER = continuous_att + '_AFTER'\n",
    "            self.prepared_data = data.copy()\n",
    "\n",
    "            self.prepared_data = data.sort_values([continuous_att])\n",
    "            label_old_value = self.prepared_data[att_AFTER].unique()\n",
    "            label_new_value = np.arange(len(label_old_value))\n",
    "            self.prepared_data[att_AFTER] = self.prepared_data[att_AFTER].replace([label_old_value],[label_new_value])\n",
    "            self.prepared_data = self.prepared_data.sort_values([att_AFTER, continuous_att])\n",
    "            \n",
    "            \n",
    "            label_simulator = self.silhouette_scores[continuous_att]\n",
    "\n",
    "            value = 0\n",
    "            upper_flag = True\n",
    "            lower_flag = True\n",
    "            value_flag = True\n",
    "            value_sufx = ''\n",
    "\n",
    "            while value < label_simulator:\n",
    "                if value_flag:\n",
    "                    upper_flag = True\n",
    "                    lower_flag = True\n",
    "                    value_sufx = ''\n",
    "                \n",
    "                value_dict = '%s%s' % (value, value_sufx)\n",
    "                if value not in dependency_dict.keys():\n",
    "                    dependency_dict.update({value_dict: {}})\n",
    "                    if upper_flag:\n",
    "                        dependency_dict[value_dict].update({\n",
    "                            'upper': {True: 0, False: 0}\n",
    "                        })\n",
    "\n",
    "                    if lower_flag:\n",
    "                        dependency_dict[value_dict].update({\n",
    "                            'lower': {True: 0, False: 0}\n",
    "                        })\n",
    "\n",
    "                for combination in self.all_combinations:\n",
    "                    _combination = '|'.join(i for i in combination)\n",
    "                    _combination_AFTER = list(list(combination) + [att_AFTER])\n",
    "\n",
    "                    self.lower_data = data.copy()\n",
    "                    self.upper_data = data.copy()\n",
    "                    \n",
    "                    self.rst = RST(\n",
    "                        self.prepared_data,\n",
    "                        continuous_columns=self.continuous_columns,\n",
    "                        decision_column_name=self.decision_column_name,\n",
    "                        include_continuous_col=True\n",
    "                    )\n",
    "                    _, dependency = self.rst.get_dependency(combination=list(_combination_AFTER))\n",
    "                    dependency_original_dict.update({_combination: dependency})\n",
    "                    \n",
    "                    indices = self.prepared_data[self.prepared_data[att_AFTER] == value].index.tolist()\n",
    "                    self._set_lower_edge_value(continuous_att, indices, value, label_simulator)\n",
    "                    self._set_upper_edge_value(continuous_att, indices, value, label_simulator)\n",
    "\n",
    "                    if value not in [0] and lower_flag:\n",
    "                        self.lower_data.loc[self.lower_edge_value[value]['idx'], (att_AFTER)] = value + 1\n",
    "                        self.rst = RST(\n",
    "                            self.lower_data,\n",
    "                            continuous_columns=self.continuous_columns,\n",
    "                            decision_column_name=self.decision_column_name,\n",
    "                            include_continuous_col=True\n",
    "                        )\n",
    "                        _, dependency = self.rst.get_dependency(\n",
    "                            combination=list(_combination_AFTER)\n",
    "                        )\n",
    "                        dependency_dict[value_dict]['lower'][dependency > dependency_original_dict[_combination]] += 1\n",
    "\n",
    "                \n",
    "                    if value not in [label_simulator - 1] and upper_flag:\n",
    "                        self.upper_data.loc[self.upper_edge_value[value]['idx'], (att_AFTER)] = value - 1\n",
    "                        self.rst = RST(\n",
    "                            self.upper_data,\n",
    "                            continuous_columns=self.continuous_columns,\n",
    "                            decision_column_name=self.decision_column_name,\n",
    "                            include_continuous_col=True\n",
    "                        )\n",
    "                        lower, dependency = self.rst.get_dependency(\n",
    "                            combination=list(_combination_AFTER)\n",
    "                        )\n",
    "                        dependency_dict[value_dict]['upper'][dependency > dependency_original_dict[_combination]] += 1\n",
    "\n",
    "                is_lower = len(self.all_combinations)/2 <= dependency_dict[value_dict]['lower'][True]\n",
    "                is_upper = len(self.all_combinations)/2 <= dependency_dict[value_dict]['upper'][True]\n",
    "                \n",
    "                if is_lower or is_upper:\n",
    "                    lower_flag=is_lower\n",
    "                    upper_flag=is_upper\n",
    "                    if is_lower:\n",
    "                        self.prepared_data.loc[self.lower_edge_value[value]['idx'], (att_AFTER)] = value + 1\n",
    "                        value_sufx = 'l'\n",
    "                    if is_upper:\n",
    "                        self.prepared_data.loc[self.upper_edge_value[value]['idx'], (att_AFTER)] = value - 1\n",
    "                        value_sufx = 'u'\n",
    "                else:\n",
    "                    value += 1\n",
    "                    value_flag = True\n",
    "\n",
    "        dependency_dict = collections.OrderedDict(sorted(dependency_dict.items()))       \n",
    "        with open('dep.json', 'w+') as fp:\n",
    "            json.dump(dependency_dict, fp)\n",
    "            \n",
    "        self.prepared_data.to_csv('prepared.csv')\n",
    "        data.to_csv('original.csv')\n",
    "        return self.prepared_data\n",
    "\n",
    "    def _dbscan_model(self):\n",
    "        result = {}\n",
    "        for att in self.continuous_columns:\n",
    "            clustering = DBSCAN(eps=1, min_samples=5).fit(\n",
    "                self._np_array_reshaped(self.data[att])\n",
    "            )\n",
    "            result[att] = clustering.labels_\n",
    "        return pd.DataFrame(result)\n",
    "\n",
    "    def _kmeans_model(self):\n",
    "        result = {}\n",
    "        for att in self.continuous_columns:\n",
    "            clustering = KMeans(n_clusters=self.silhouette_scores[att], random_state=41).fit(\n",
    "                self._np_array_reshaped(self.scaled_data[att])\n",
    "            )\n",
    "            result[att] = clustering.labels_\n",
    "        return pd.DataFrame(result)\n",
    "\n",
    "    def _np_array_reshaped(self, data, reshape=(-1, 1)):\n",
    "        return np.array(data.tolist()).reshape(reshape[0], reshape[1])\n",
    "\n",
    "    def _check_continuous(self, continous_columns: list = []):\n",
    "        top_n = self.checker_top_n\n",
    "        likely = []\n",
    "\n",
    "        # check if attribute is continuous or discrete dataframe\n",
    "        for var in self.data.columns:\n",
    "            if self.dis_checker == 'topN':\n",
    "                # Check if the top n unique values account for more than a certain proportion of all values\n",
    "                if 1.*self.data[var].value_counts(normalize=True).head(top_n).sum() < 0.5:\n",
    "                    likely.append(var)\n",
    "            elif self.dis_checker == 'ratio':\n",
    "                # Find the ratio of number of unique values to the total number of unique values. Something like the following\n",
    "                if 1.*self.data[var].nunique()/self.data[var].count() > 0.5:\n",
    "                    likely.append(var)\n",
    "\n",
    "        common_names = ['id']\n",
    "\n",
    "        return [x for x in likely if x.lower() not in common_names]\n",
    "\n",
    "    def _labeling_discrete(self, data):\n",
    "\n",
    "        data_endocded = data.copy()\n",
    "\n",
    "        for col in data_endocded:\n",
    "            if col not in self.continuous_columns:\n",
    "                le = self.encoder.fit(data_endocded[col])\n",
    "                data_endocded[col] = self.encoder.transform(data_endocded[col])\n",
    "                self.encoder_dict[col] = self.encoder\n",
    "        return data_endocded\n",
    "\n",
    "    def _scaling_continuous(self):\n",
    "\n",
    "        data_cluster = self.data[self.continuous_columns].copy()\n",
    "        scaled_columns = self.scaler.fit_transform(data_cluster)\n",
    "        self.scaled_data = self.data.copy()\n",
    "        self.scaled_data[self.continuous_columns] = scaled_columns\n",
    "\n",
    "        return self.scaled_data\n",
    "\n",
    "    def _get_silhouette_score(self):\n",
    "        scores = {}\n",
    "        for att in self.continuous_columns:\n",
    "            temp_score = []\n",
    "            scores[att] = 3\n",
    "            for n_clusters in range(3, 9):\n",
    "                # Initialize the clusterer with n_clusters value and a random generator\n",
    "                # seed of 10 for reproducibility.\n",
    "                clusterer = KMeans(n_clusters=n_clusters, random_state=10)\n",
    "                cluster_labels = clusterer.fit_predict(\n",
    "                    self._np_array_reshaped(self.scaled_data[att]))\n",
    "\n",
    "                # The silhouette_score gives the average value for all the samples.\n",
    "                # This gives a perspective into the density and separation of the formed\n",
    "                # clusters\n",
    "                silhouette_avg = silhouette_score(\n",
    "                    self._np_array_reshaped(self.scaled_data[att]), cluster_labels)\n",
    "                temp_score.append(silhouette_avg)\n",
    "            scores[att] = temp_score.index(max(temp_score)) + 3\n",
    "        return scores\n",
    "\n",
    "    def get_combinations(self, comb_max_depth: int = None):\n",
    "        if not comb_max_depth:\n",
    "            comb_max_depth = self.comb_max_depth\n",
    "        combX = []\n",
    "        for idx, _ in enumerate(self.discrete_columns):\n",
    "            if comb_max_depth and comb_max_depth == idx:\n",
    "                break\n",
    "            combX.extend(list(combinations(self.discrete_columns, idx + 1)))\n",
    "\n",
    "        return sorted(combX, key=len)\n",
    "    \n",
    "    def _set_lower_edge_value(self, att, indices, value, s_c):\n",
    "        same_value = self.prepared_data.loc[indices][att].values.tolist()\n",
    "        lower_same_value = self.prepared_data[att].isin([same_value[0]])\n",
    "        lower_temp = self.prepared_data[lower_same_value]\n",
    "        self.lower_edge_value.update({\n",
    "            value: {\n",
    "                'idx': lower_temp.index.tolist(),\n",
    "                'value': lower_temp.values.tolist()[0][0],\n",
    "            }\n",
    "        })\n",
    "\n",
    "        return self.lower_edge_value\n",
    "\n",
    "    def _set_upper_edge_value(self, att, indices, value, s_c):\n",
    "        same_value = self.prepared_data.loc[indices][att].values.tolist()\n",
    "        upper_same_value = self.prepared_data[att].isin([same_value[-1]])\n",
    "        upper_temp = self.prepared_data[upper_same_value]\n",
    "        self.upper_edge_value.update({\n",
    "            value: {\n",
    "                'idx': upper_temp.index.tolist(),\n",
    "                'value': upper_temp.values.tolist()[0][0],\n",
    "            }\n",
    "        })\n",
    "\n",
    "        return self.upper_edge_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annual_Premium    3\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Driving_License</th>\n",
       "      <th>Region_Code</th>\n",
       "      <th>Previously_Insured</th>\n",
       "      <th>Vehicle_Age</th>\n",
       "      <th>Vehicle_Damage</th>\n",
       "      <th>Annual_Premium</th>\n",
       "      <th>Policy_Sales_Channel</th>\n",
       "      <th>Response</th>\n",
       "      <th>Annual_Premium_AFTER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2630.0</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2630.0</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2630.0</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2630.0</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>549</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2630.0</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>61536.0</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>64215.0</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>71026.0</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>75977.0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>95130.0</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>600 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Gender  Driving_License  Region_Code  Previously_Insured  Vehicle_Age  \\\n",
       "122       1                1           40                   0            0   \n",
       "168       1                1           45                   0            1   \n",
       "332       0                1           27                   0            2   \n",
       "335       1                1           18                   0            0   \n",
       "549       1                1           27                   0            0   \n",
       "..      ...              ...          ...                 ...          ...   \n",
       "471       1                1            8                   1            1   \n",
       "344       1                1            8                   0            1   \n",
       "162       1                1           27                   0            0   \n",
       "301       0                1           27                   0            1   \n",
       "496       1                1           27                   1            1   \n",
       "\n",
       "     Vehicle_Damage  Annual_Premium  Policy_Sales_Channel  Response  \\\n",
       "122               1          2630.0                    38         1   \n",
       "168               1          2630.0                    34         0   \n",
       "332               1          2630.0                    35         1   \n",
       "335               1          2630.0                    13         1   \n",
       "549               1          2630.0                    13         1   \n",
       "..              ...             ...                   ...       ...   \n",
       "471               0         61536.0                    30         0   \n",
       "344               1         64215.0                    30         0   \n",
       "162               1         71026.0                    24         1   \n",
       "301               1         75977.0                    13         0   \n",
       "496               0         95130.0                    30         0   \n",
       "\n",
       "     Annual_Premium_AFTER  \n",
       "122                     0  \n",
       "168                     0  \n",
       "332                     0  \n",
       "335                     0  \n",
       "549                     0  \n",
       "..                    ...  \n",
       "471                     2  \n",
       "344                     2  \n",
       "162                     2  \n",
       "301                     2  \n",
       "496                     2  \n",
       "\n",
       "[600 rows x 10 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = data.copy()\n",
    "df = df.sample(600, random_state=41) # 24\n",
    "df['Response'].value_counts().plot(kind='bar')\n",
    "df.drop(['Vintage', 'Age'], axis=1, inplace=True)\n",
    "df.nunique()\n",
    "\n",
    "drst = DRST(comb_max_depth=2, decision_column_name='Response')\n",
    "drst_fit = drst.fit(df)\n",
    "drst_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0c34a26dce7bb7449e42c35f5e9b82d8f7c9f77a71ba73bf71e175f0017805aa"
  },
  "kernelspec": {
   "display_name": "Python 3.10.3 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
