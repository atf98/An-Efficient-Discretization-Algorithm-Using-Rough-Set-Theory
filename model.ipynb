{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "from sklearn.cluster import DBSCAN, KMeans\n",
    "from sklearn.neighbors import KernelDensity\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, OneHotEncoder\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.neighbors import KernelDensity\n",
    "from scipy.signal import argrelextrema\n",
    "import kmeans1d\n",
    "'''\n",
    "kmeans1d\n",
    "\n",
    "A Python library with an implementation of k-means clustering on 1D data, based on the algorithm in (Xiaolin 1991), as presented in section 2.2 of (Gronlund et al., 2017).\n",
    "\n",
    "Globally optimal k-means clustering is NP-hard for multi-dimensional data. Lloyd's algorithm is a popular approach for finding a locally optimal solution. For 1-dimensional data, there are polynomial time algorithms. The algorithm implemented here is a O(kn + n log n) dynamic programming algorithm for finding the globally optimal k clusters for n 1D data points.\n",
    "\n",
    "The code is written in C++, and wrapped with Python.\n",
    "'''\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shape (381109, 11)\n",
    "data = pd.read_csv('datasets/d1.csv')\n",
    "# data_1 = data_1.drop(['id'], axis=1)\n",
    "\n",
    "# data_2 = pd.read_csv('datasets/d2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                      200\n",
       "Gender                    2\n",
       "Age                      51\n",
       "Driving_License           2\n",
       "Region_Code              38\n",
       "Previously_Insured        2\n",
       "Vehicle_Age               3\n",
       "Vehicle_Damage            2\n",
       "Annual_Premium          166\n",
       "Policy_Sales_Channel     17\n",
       "Vintage                 151\n",
       "Response                  2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "freq = pd.DataFrame({'Response':['0', '1'], 'nostoextract':[46710, 46710], })\n",
    "def bootstrap(data, freq):\n",
    "    freq = freq.set_index('Response')\n",
    "\n",
    "    # This function will be applied on each group of instances of the same\n",
    "    # class in `data`.\n",
    "    def sampleClass(classgroup):\n",
    "        cls = classgroup['Response'].iloc[0]\n",
    "        nDesired = freq.nostoextract[cls]\n",
    "        nRows = len(classgroup)\n",
    "\n",
    "        nSamples = min(nRows, nDesired)\n",
    "        return classgroup.sample(nSamples)\n",
    "\n",
    "    samples = data.groupby('Response').apply(sampleClass)\n",
    "\n",
    "    # If you want a new index with ascending values\n",
    "    # samples.index = range(len(samples))\n",
    "\n",
    "    # If you want an index which is equal to the row in `data` where the sample\n",
    "    # came from\n",
    "    samples.index = samples.index.get_level_values(1)\n",
    "\n",
    "    # If you don't change it then you'll have a multiindex with level 0\n",
    "    # being the class and level 1 being the row in `data` where\n",
    "    # the sample came from.\n",
    "\n",
    "    return samples\n",
    "\n",
    "data = bootstrap(data,freq)\n",
    "df = data.copy()\n",
    "df = df.sample(200, random_state=24) # 24\n",
    "df['Response'].value_counts().plot(kind='bar') \n",
    "df.nunique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Age': 3, 'Annual_Premium': 8, 'Vintage': 5}\n",
      "Age               3\n",
      "Annual_Premium    8\n",
      "Vintage           5\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "\n",
    "\n",
    "class Error(Exception):\n",
    "    \"\"\"Base class for other exceptions\"\"\"\n",
    "    pass\n",
    "\n",
    "\n",
    "class NotMatchResult(Error):\n",
    "    \"\"\"Raised when the input value is too small\"\"\"\n",
    "    pass\n",
    "\n",
    "\n",
    "class DRST:\n",
    "    '''\n",
    "        An Efficient Discretization Algorithm Using Rough Set Theory\n",
    "\n",
    "        ...\n",
    "\n",
    "        Attributes\n",
    "        ----------\n",
    "        checker_type : str='topN'\n",
    "            Type of the checker of data to determind wether data column is Continous or Discrete\n",
    "\n",
    "        Methods\n",
    "        -------\n",
    "        fit(x: DataFrame, continous_columns: list)\n",
    "\n",
    "        Note\n",
    "        -------\n",
    "\n",
    "        Example\n",
    "        -------\n",
    "\n",
    "\n",
    "    '''\n",
    "\n",
    "    def __init__(self, checker_type: str = 'topN'):\n",
    "        # Primary Data Information\n",
    "        self.data = None\n",
    "        self.columns = None\n",
    "        self.continuous_columns = None\n",
    "        self.discrete_columns = None\n",
    "        self.scaled_data = None\n",
    "\n",
    "        # Secondary Data infromation\n",
    "        self.data_after_INI = None\n",
    "        self.silhouette_scores = None\n",
    "\n",
    "        # check_discrete\n",
    "        self.dis_check_threshold = 0.5\n",
    "        self.dis_checker = checker_type  # ratio\n",
    "        self.checker_top_n = 10  # defult number of top N for topN checker\n",
    "\n",
    "        # Config Tools\n",
    "        self.scaler = StandardScaler()\n",
    "        self.natural_interval_model = 'dbscan'\n",
    "        self.NIM_message = 'Model for initiat the natural intervals cannot be blank'\n",
    "\n",
    "    def fit(\n",
    "            self,\n",
    "            x: pd.DataFrame,\n",
    "            continous_columns: list = [],\n",
    "            natural_interval_model: str = 'kmeans'\n",
    "    ):\n",
    "        \"\"\"Discretization using Rough Sets Theory (RST).\n",
    "\n",
    "        Fit `x` to an efficient intervals using the concept of RST \n",
    "        * asd\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : DataFrame\n",
    "            Full DataFrame (default is None)\n",
    "\n",
    "        continous_columns : list\n",
    "            Determind names of column(s) in the DataFarme as Continuous data. If `None` a function _check_continuous triger to determind names of column(s).\n",
    "\n",
    "        Raises\n",
    "        ------\n",
    "        NotMatchResult\n",
    "            If continous_columns `~None` model check the input with the checker determation if didn't match the result\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        # Reduct Data Intervals phase: Pre-process of discretization, intiate classification\n",
    "        # Pre-process of discretization\n",
    "        self.data = x\n",
    "        self.columns = self.data.columns\n",
    "        self.continuous_columns = continous_columns if continous_columns else self._check_continuous()\n",
    "        self.discrete_columns = list(set(self.columns).difference(self.continuous_columns))\n",
    "        self.scaled_data = self._scaling_continuous()\n",
    "        self.silhouette_scores = self._get_silhouette_score()\n",
    "        print(self.silhouette_scores)\n",
    "\n",
    "        # Intiate classification\n",
    "        self.data_after_INI = getattr(self, '_%s_model' % natural_interval_model, lambda: self.NIM_message)()\n",
    "        print(self.data_after_INI.nunique())\n",
    "        self.data_after_INI.sort_values(['Annual_Premium']).to_csv('%s_model.csv' % natural_interval_model)\n",
    "        return self.data_after_INI\n",
    "    \n",
    "    def _dbscan_model(self):\n",
    "        result = {}\n",
    "        for att in self.continuous_columns:\n",
    "            clustering = DBSCAN(eps=1, min_samples=5).fit(\n",
    "                self._np_array_reshaped(self.data[att])\n",
    "            )\n",
    "            result[att] = clustering.labels_\n",
    "        return pd.DataFrame(result)\n",
    "\n",
    "    def _kmeans_model(self):\n",
    "        result = {}\n",
    "        for att in self.continuous_columns:\n",
    "            clustering = KMeans(n_clusters=self.silhouette_scores[att]).fit(\n",
    "                self._np_array_reshaped(self.scaled_data[att])\n",
    "            )\n",
    "            result[att] = clustering.labels_\n",
    "        return pd.DataFrame(result)\n",
    "\n",
    "    def _np_array_reshaped(self, data, reshape=(-1, 1)):\n",
    "        return np.array(data.tolist()).reshape(reshape[0], reshape[1])\n",
    "\n",
    "    def _check_continuous(self, continous_columns: list = []):\n",
    "        top_n = self.checker_top_n\n",
    "        likely = []\n",
    "\n",
    "        # check if attribute is continuous or discrete dataframe\n",
    "        for var in self.data.columns:\n",
    "            if self.dis_checker == 'topN':\n",
    "                # Check if the top n unique values account for more than a certain proportion of all values\n",
    "                if 1.*self.data[var].value_counts(normalize=True).head(top_n).sum() < 0.5:\n",
    "                    likely.append(var)\n",
    "            elif self.dis_checker == 'ratio':\n",
    "                # Find the ratio of number of unique values to the total number of unique values. Something like the following\n",
    "                if 1.*self.data[var].nunique()/self.data[var].count() > 0.5:\n",
    "                    likely.append(var)\n",
    "\n",
    "        common_names = ['id']\n",
    "        \n",
    "        return [x for x in likely if x.lower() not in common_names]\n",
    "\n",
    "    def _scaling_continuous(self):\n",
    "        \n",
    "        data_cluster = self.data[self.continuous_columns].copy()\n",
    "        scaled_columns = self.scaler.fit_transform(data_cluster)\n",
    "        self.scaled_data = self.data.copy()\n",
    "        self.scaled_data[self.continuous_columns] = scaled_columns\n",
    "\n",
    "        return self.scaled_data\n",
    "        \n",
    "    def _get_silhouette_score(self):\n",
    "        scores = {}\n",
    "        for att in self.continuous_columns:\n",
    "            temp_score = []\n",
    "            scores[att] = 3\n",
    "            for n_clusters in range(3,9):\n",
    "                # Initialize the clusterer with n_clusters value and a random generator\n",
    "                # seed of 10 for reproducibility.\n",
    "                clusterer = KMeans(n_clusters=n_clusters, random_state=10)\n",
    "                cluster_labels = clusterer.fit_predict(self._np_array_reshaped(self.scaled_data[att]))\n",
    "\n",
    "                # The silhouette_score gives the average value for all the samples.\n",
    "                # This gives a perspective into the density and separation of the formed\n",
    "                # clusters\n",
    "                silhouette_avg = silhouette_score(self._np_array_reshaped(self.scaled_data[att]), cluster_labels)\n",
    "                temp_score.append(silhouette_avg)\n",
    "            scores[att] = temp_score.index(max(temp_score)) + 3\n",
    "        return scores\n",
    "\n",
    "\n",
    "drst = DRST()\n",
    "# drst.fit(data_1, natural_interval_model='kmeans', continous_columns=['months_as_customer','total_claim_amount'])\n",
    "# drst.fit(data_1, natural_interval_model='kmeans')\n",
    "\n",
    "drst_fit = drst.fit(df, natural_interval_model='kmeans')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0c34a26dce7bb7449e42c35f5e9b82d8f7c9f77a71ba73bf71e175f0017805aa"
  },
  "kernelspec": {
   "display_name": "Python 3.10.3 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
