{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.DRST import DRST\n",
    "\n",
    "import os\n",
    "import warnings\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn import tree, metrics \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_dir = os.getcwd()\n",
    "# Path('%s\\\\output\\\\%s\\\\%s' % (current_dir, model, pat)).mkdir(parents=True, exist_ok=True)\n",
    "# file1 = open('%s\\\\output\\\\%s\\\\%s\\\\result.txt' % (current_dir, model, pat), 'w+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {\n",
    "    'Health Insurance': {\n",
    "        'path': 'datasets\\\\health_insurance.csv',\n",
    "        'outputPath': 'output\\\\Health Insurance',\n",
    "        'nameregex': 'health_insurance',\n",
    "        'dataset_size': 'normal',\n",
    "        'class_name': 'class',\n",
    "    },\n",
    "    'D2': {\n",
    "        'path': 'datasets\\\\d2.csv',\n",
    "        'outputPath': 'output\\\\D2',\n",
    "        'nameregex': 'd2',\n",
    "        'dataset_size': 'normal',\n",
    "        'class_name': 'fraud_reported',\n",
    "    },\n",
    "    }\n",
    "\n",
    "datasets_names = list(datasets.keys())\n",
    "test_ration = {'20-80': [20, 80], '30-70': [30, 70], '40-60': [40, 60]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_c_c = ['Annual_Premium', 'Vintage', 'Age']\n",
    "def encoder(d):\n",
    "    le = LabelEncoder()\n",
    "    encoder_dict = dict()\n",
    "    data_endocded = d.copy()\n",
    "\n",
    "    for col in data_endocded:\n",
    "        if col not in ex_c_c:\n",
    "            le = le.fit(data_endocded[col])\n",
    "            data_endocded[col] = le.transform(data_endocded[col])\n",
    "            encoder_dict[col] = le\n",
    "    return data_endocded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annual_Premium    3\n",
      "Vintage           3\n",
      "Age               4\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data = pd.read_csv(datasets['Health Insurance']['path'])\n",
    "df = data.copy()\n",
    "df = df.sample(350, random_state=41) # 41\n",
    "# df.drop(['Vintage', 'Age'], axis=1, inplace=True)\n",
    "\n",
    "Path('%s\\\\%s' % (current_dir, datasets['Health Insurance']['outputPath'])).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "drst = DRST(comb_max_depth=1, decision_column_name='Response', output_loction=datasets['Health Insurance']['outputPath'])\n",
    "drst_fit, continuous_columns = drst.fit(df, continous_columns=['Annual_Premium', 'Vintage', 'Age'])\n",
    "drst_fit.drop(continuous_columns, axis=1, inplace=True)\n",
    "\n",
    "datasets['Health Insurance'].update({\n",
    "    'drop_column': ['Vintage', 'Age'],\n",
    "    'class_name': 'Response',\n",
    "    'data': df,\n",
    "    'data_original': encoder(df),\n",
    "    'data_drst': drst_fit\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n",
      "policy_annual_premium    7\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "D2 = pd.read_csv(datasets['D2']['path'])\n",
    "D2.drop(['months_as_customer', 'age', 'total_claim_amount'], axis=1, inplace=True)\n",
    "drst1 = DRST(comb_max_depth=1, decision_column_name='fraud_reported', output_loction=datasets['D2']['outputPath'])\n",
    "drst_fit1, continuous_columns= drst1.fit(D2, continous_columns=['policy_annual_premium'])\n",
    "drst_fit1['policy_annual_premium'] = drst_fit1['policy_annual_premium_AFTER']\n",
    "drst_fit1.drop('policy_annual_premium_AFTER', axis=1, inplace=True)\n",
    "\n",
    "datasets['D2'].update({\n",
    "            'drop_column': [],\n",
    "            'data': D2,'data_original': encoder(D2),\n",
    "            'data_drst': drst_fit1\n",
    "            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Test_RFC(test_name, test_split='20-80', print_flag=False):\n",
    "    '''\n",
    "        test_split is the percentage of the splitting for the data, which train_split =  100 - test_split\n",
    "    '''\n",
    "    for mode in ['data_original', 'data_drst']:\n",
    "        # Scraping info of dataset from datasets variable\n",
    "        data = datasets[test_name][mode].copy()\n",
    "        class_name = datasets[test_name]['class_name']\n",
    "        regex_name = datasets[test_name]['nameregex']\n",
    "\n",
    "        \n",
    "        file = open('%s\\\\output\\\\accuracy_result.text' % (current_dir), 'a+')\n",
    "        \n",
    "        Path('%s\\\\output\\\\%s\\\\RandomForestClassifier\\\\%s' % (current_dir, test_name, test_split)).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        feature_names = [i for i in data.columns if i != class_name]\n",
    "        X, y = data[feature_names], data[class_name]\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = test_ration[test_split][0]/100, random_state=0)\n",
    "        # clf = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "        clf = RandomForestClassifier(n_estimators = 100, random_state=21) \n",
    "        \n",
    "        # Training the model on the training dataset\n",
    "        # fit function is used to train the model using the training sets as parameters\n",
    "        clf.fit(X_train, y_train)\n",
    "        \n",
    "        # performing predictions on the test dataset\n",
    "        y_pred = clf.predict(X_test)\n",
    "        \n",
    "        # metrics are used to find accuracy or error\n",
    "        report = classification_report(y_test, y_pred, output_dict=True)\n",
    "        report.update({'Rules Number': len(tree.export_text(clf.estimators_[0]))})\n",
    "        report_df = pd.DataFrame(report).transpose()\n",
    "        report_df.to_csv('%s\\\\output\\\\%s\\\\RandomForestClassifier\\\\%s\\\\report-CLFTester-%s-%s.csv' % (current_dir, test_name, test_split, regex_name, mode))\n",
    "        file.write(\"data %s:ACCURACY for data %s in model RandomForestClassifier with split ration %s === %s\\n\" % (test_name,mode,test_split,metrics.accuracy_score(y_test, y_pred)))\n",
    "        if print_flag:\n",
    "            # using metrics module for accuracy calculation\n",
    "            print('------------------------')\n",
    "            print(test_name)\n",
    "            print('------------------------')\n",
    "            print(\"Number of rules Extracted from the model: %s\" % len(tree.export_text(clf.estimators_[0])))\n",
    "            print(\"ACCURACY: %s\" % (metrics.accuracy_score(y_test, y_pred)))\n",
    "            print(\"CLASSIFICATION REPORT \\n %s\" % report)\n",
    "\n",
    "        tree.plot_tree(clf.estimators_[0],\n",
    "                    feature_names = feature_names, \n",
    "                    class_names=class_name,\n",
    "                    filled = True)\n",
    "        plt.savefig('%s\\\\output\\\\%s\\\\RandomForestClassifier\\\\%s\\\\CLFTester-%s-%s.png' % (current_dir, test_name, test_split, regex_name, mode))\n",
    "        plt.close()\n",
    "    file.write('\\n')\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Test_DT(test_name, test_split='20-80', print_flag=False):\n",
    "    '''\n",
    "        test_split is the percentage of the splitting for the data, which train_split =  100 - test_split\n",
    "    '''\n",
    "    for mode in ['data_original', 'data_drst']:\n",
    "        # Scraping info of dataset from datasets variable\n",
    "        data = datasets[test_name][mode].copy()\n",
    "        class_name = datasets[test_name]['class_name']\n",
    "        regex_name = datasets[test_name]['nameregex']\n",
    "\n",
    "        Path('%s\\\\output\\\\accuracy_result.text' % (current_dir)).touch(exist_ok=True)\n",
    "        file = open('%s\\\\output\\\\accuracy_result.text' % (current_dir), 'a+')\n",
    "        Path('%s\\\\output\\\\%s\\\\DecisionTrees\\\\%s' % (current_dir, test_name, test_split)).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        feature_names = [i for i in data.columns if i != class_name]\n",
    "        X, y = data[feature_names], data[class_name]\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = test_ration[test_split][0]/100, random_state=1)\n",
    "        clf = tree.DecisionTreeClassifier(criterion='entropy', splitter='random')\n",
    "        \n",
    "        # Training the model on the training dataset\n",
    "        # fit function is used to train the model using the training sets as parameters\n",
    "        clf.fit(X_train, y_train)\n",
    "        \n",
    "        # performing predictions on the test dataset\n",
    "        y_pred = clf.predict(X_test)\n",
    "        \n",
    "        # metrics are used to find accuracy or error\n",
    "        report = classification_report(y_test, y_pred, output_dict=True)\n",
    "        report.update({'Rules Number': len(tree.export_text(clf))})\n",
    "        report_df = pd.DataFrame(report).transpose()\n",
    "        report_df.to_csv('%s\\\\output\\\\%s\\\\DecisionTrees\\\\%s\\\\report-CLFTester-%s-%s.csv' % (current_dir, test_name, test_split, regex_name, mode))\n",
    "        file.write(\"data %s:ACCURACY for data %s in model DecisionTrees with split ration %s === %s\\n\" % (test_name,mode,test_split,metrics.accuracy_score(y_test, y_pred)))\n",
    "        if print_flag:\n",
    "            # using metrics module for accuracy calculation\n",
    "            print('------------------------')\n",
    "            print(test_name)\n",
    "            print('------------------------')\n",
    "            print(\"Number of rules Extracted from the model: %s\" % len(tree.export_text(clf.estimators_[0])))\n",
    "            print(\"ACCURACY: %s\" % (metrics.accuracy_score(y_test, y_pred)))\n",
    "            print(\"CLASSIFICATION REPORT \\n %s\" % report)\n",
    "\n",
    "        tree.plot_tree(clf,\n",
    "                    feature_names = feature_names, \n",
    "                    class_names=class_name,\n",
    "                    filled = True)\n",
    "        plt.savefig('%s\\\\output\\\\%s\\\\DecisionTrees\\\\%s\\\\CLFTester-%s-%s.png' % (current_dir, test_name, test_split, regex_name, mode))\n",
    "        plt.close()\n",
    "    file.write('\\n')\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def Test_XG(test_name, test_split='20-80', print_flag=False):\n",
    "    '''\n",
    "        test_split is the percentage of the splitting for the data, which train_split =  100 - test_split\n",
    "    '''\n",
    "    for mode in ['data_original', 'data_drst']:\n",
    "        # Scraping info of dataset from datasets variable\n",
    "        data = datasets[test_name][mode].copy()\n",
    "        class_name = datasets[test_name]['class_name']\n",
    "        regex_name = datasets[test_name]['nameregex']\n",
    "\n",
    "        Path('%s\\\\output\\\\accuracy_result.text' % (current_dir)).touch(exist_ok=True)\n",
    "        file = open('%s\\\\output\\\\accuracy_result.text' % (current_dir), 'a+')\n",
    "        Path('%s\\\\output\\\\%s\\\\XGBRFClassifier\\\\%s' % (current_dir, test_name, test_split)).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        feature_names = [i for i in data.columns if i != class_name]\n",
    "        X, y = data[feature_names], data[class_name]\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = test_ration[test_split][0]/100, random_state=0)\n",
    "        xg_reg = xgb.XGBRFClassifier()\n",
    "        # Training the model on the training dataset\n",
    "        # fit function is used to train the model using the training sets as parameters\n",
    "        xg_reg.fit(X_train,y_train)\n",
    "        # performing predictions on the test dataset\n",
    "        y_pred = xg_reg.predict(X_test)\n",
    "        \n",
    "        # # metrics are used to find accuracy or error\n",
    "        report = classification_report(y_test, y_pred, output_dict=True)\n",
    "        report.update({'Rules Number': xg_reg._Booster.trees_to_dataframe().shape[0]})\n",
    "        report_df = pd.DataFrame(report).transpose()\n",
    "        report_df.to_csv('%s\\\\output\\\\%s\\\\XGBRFClassifier\\\\%s\\\\report-CLFTester-%s-%s.csv' % (current_dir, test_name, test_split, regex_name, mode))\n",
    "        file.write(\"data %s:ACCURACY for data %s in model XGBRFClassifier with split ration %s === %s\\n\" % (test_name,mode,test_split,metrics.accuracy_score(y_test, y_pred)))\n",
    "        if print_flag:\n",
    "            # using metrics module for accuracy calculation\n",
    "            print('------------------------')\n",
    "            print(test_name)\n",
    "            print('------------------------')\n",
    "            print(\"Number of rules Extracted from the model: %s\" % len(tree.export_text(xg_reg._Booster.trees_to_dataframe().shape[0])))\n",
    "            print(\"ACCURACY: %s\" % (metrics.accuracy_score(y_test, y_pred)))\n",
    "            print(\"CLASSIFICATION REPORT \\n %s\" % report)\n",
    "        \n",
    "        fig, ax = plt.subplots(figsize=(30, 30))\n",
    "        xgb.plot_tree(xg_reg, num_trees=4, ax=ax)\n",
    "        # tree.plot_tree(clf,\n",
    "        #             feature_names = feature_names, \n",
    "        #             class_names=class_name,\n",
    "        #             filled = True)\n",
    "        plt.savefig('%s\\\\output\\\\%s\\\\XGBRFClassifier\\\\%s\\\\CLFTester-%s-%s.png' % (current_dir, test_name, test_split, regex_name, mode))\n",
    "        plt.close()\n",
    "    file.write('\\n')\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "def Test_bnb(test_name, test_split='20-80', print_flag=False):\n",
    "    '''\n",
    "        test_split is the percentage of the splitting for the data, which train_split =  100 - test_split\n",
    "    '''\n",
    "    for mode in ['data_original', 'data_drst']:\n",
    "        # Scraping info of dataset from datasets variable\n",
    "        data = datasets[test_name][mode].copy()\n",
    "        class_name = datasets[test_name]['class_name']\n",
    "        regex_name = datasets[test_name]['nameregex']\n",
    "\n",
    "        Path('%s\\\\output\\\\accuracy_result.text' % (current_dir)).touch(exist_ok=True)\n",
    "        file = open('%s\\\\output\\\\accuracy_result.text' % (current_dir), 'a+')\n",
    "        Path('%s\\\\output\\\\%s\\\\BernoulliNB\\\\%s' % (current_dir, test_name, test_split)).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        feature_names = [i for i in data.columns if i != class_name]\n",
    "        X, y = data[feature_names], data[class_name]\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = test_ration[test_split][0]/100, random_state=11)\n",
    "        bnb = BernoulliNB()\n",
    "        # Training the model on the training dataset\n",
    "        # fit function is used to train the model using the training sets as parameters\n",
    "        bnb.fit(X_train,y_train)\n",
    "        # performing predictions on the test dataset\n",
    "        y_pred = bnb.predict(X_test)\n",
    "        \n",
    "        # # metrics are used to find accuracy or error\n",
    "        report = classification_report(y_test, y_pred, output_dict=True)\n",
    "        # report.update({'Rules Number': bnb._Booster.trees_to_dataframe().shape[0]})\n",
    "        report_df = pd.DataFrame(report).transpose()\n",
    "        report_df.to_csv('%s\\\\output\\\\%s\\\\BernoulliNB\\\\%s\\\\report-CLFTester-%s-%s.csv' % (current_dir, test_name, test_split, regex_name, mode))\n",
    "        file.write(\"data %s:ACCURACY for data %s in model BernoulliNB with split ration %s === %s\\n\" % (test_name,mode,test_split,metrics.accuracy_score(y_test, y_pred)))\n",
    "    file.write('\\n')\n",
    "    file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "Path('%s\\\\output\\\\accuracy_result.text' % (current_dir)).touch(exist_ok=True)\n",
    "file = open('%s\\\\output\\\\accuracy_result.text' % (current_dir), 'a+')\n",
    "file.write('___________________________________________________\\n')\n",
    "file.write('All RandomForestClassifier Results\\n')\n",
    "file.write('___________________________________________________\\n')\n",
    "file.close()\n",
    "for tp in test_ration.keys():\n",
    "    # Health Insurance Data Tester\n",
    "    Test_RFC(datasets_names[0], test_split=tp)\n",
    "\n",
    "    # Play Tennis Three Attrubite Data Tester\n",
    "    Test_RFC(datasets_names[1], test_split=tp)\n",
    "    \n",
    "    # Play Tennis Four Attrubite Data Tester\n",
    "    # Test_RFC(datasets_names[2], test_split=tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "Path('%s\\\\output\\\\accuracy_result.text' % (current_dir)).touch(exist_ok=True)\n",
    "file = open('%s\\\\output\\\\accuracy_result.text' % (current_dir), 'a+')\n",
    "file.write('___________________________________________________\\n')\n",
    "file.write('All DecisionTrees Results\\n')\n",
    "file.write('___________________________________________________\\n')\n",
    "file.close()\n",
    "for tp in test_ration.keys():\n",
    "    # Health Insurance Data Tester\n",
    "    Test_DT(datasets_names[0], test_split=tp)\n",
    "\n",
    "    # Play Tennis Three Attrubite Data Tester\n",
    "    Test_DT(datasets_names[1], test_split=tp)\n",
    "    \n",
    "    # Play Tennis Four Attrubite Data Tester\n",
    "    # Test_RFC(datasets_names[2], test_split=tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "Path('%s\\\\output\\\\accuracy_result.text' % (current_dir)).touch(exist_ok=True)\n",
    "file = open('%s\\\\output\\\\accuracy_result.text' % (current_dir), 'a+')\n",
    "file.write('___________________________________________________\\n')\n",
    "file.write('All XGBRFClassifier Results\\n')\n",
    "file.write('___________________________________________________\\n')\n",
    "file.close()\n",
    "for tp in test_ration.keys():\n",
    "    # Health Insurance Data Tester\n",
    "    Test_XG(datasets_names[0], test_split=tp)\n",
    "\n",
    "    # Play Tennis Three Attrubite Data Tester\n",
    "    Test_XG(datasets_names[1], test_split=tp)\n",
    "    \n",
    "    # Play Tennis Four Attrubite Data Tester\n",
    "    # Test_RFC(datasets_names[2], test_split=tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path('%s\\\\output\\\\accuracy_result.text' % (current_dir)).touch(exist_ok=True)\n",
    "# file = open('%s\\\\output\\\\accuracy_result.text' % (current_dir), 'a+')\n",
    "# file.write('___________________________________________________\\n')\n",
    "# file.write('All BernoulliNB Results\\n')\n",
    "# file.write('___________________________________________________\\n')\n",
    "# file.close()\n",
    "# for tp in test_ration.keys():\n",
    "#     # Health Insurance Data Tester\n",
    "#     Test_bnb(datasets_names[0], test_split=tp)\n",
    "\n",
    "#     # Play Tennis Three Attrubite Data Tester\n",
    "#     Test_bnb(datasets_names[1], test_split=tp)\n",
    "    \n",
    "#     # Play Tennis Four Attrubite Data Tester\n",
    "#     # Test_RFC(datasets_names[2], test_split=tp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.3 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e99f971b6d48a9f8afab1d34758ddbb9a87e8265f2671e414e3fdd21b2f0ea4e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
