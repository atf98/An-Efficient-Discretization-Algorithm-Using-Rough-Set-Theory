{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tooldev import RST\n",
    "from tooldev.sample import bootstrap\n",
    "\n",
    "from itertools import combinations\n",
    "\n",
    "import re\n",
    "import random\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import collections\n",
    "\n",
    "from sklearn.cluster import DBSCAN, KMeans\n",
    "from sklearn.neighbors import KernelDensity\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, OneHotEncoder\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.neighbors import KernelDensity\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "\n",
    "class Error(Exception):\n",
    "    \"\"\"Base class for other exceptions\"\"\"\n",
    "    pass\n",
    "\n",
    "\n",
    "class NotMatchResult(Error):\n",
    "    \"\"\"Raised when the input value is too small\"\"\"\n",
    "    pass\n",
    "\n",
    "\n",
    "class DRST:\n",
    "    '''\n",
    "        An Efficient Discretization Algorithm Using Rough Set Theory\n",
    "\n",
    "        ...\n",
    "\n",
    "        Attributes\n",
    "        ----------\n",
    "        checker_type : str='topN'\n",
    "            Type of the checker of data to determind wether data column is Continous or Discrete\n",
    "\n",
    "        Methods\n",
    "        -------\n",
    "        fit(x: DataFrame, continous_columns: list)\n",
    "\n",
    "        Note\n",
    "        -------\n",
    "\n",
    "        Example\n",
    "        -------\n",
    "\n",
    "\n",
    "    '''\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        checker_type: str = 'topN',\n",
    "        comb_max_depth: int = None,\n",
    "        decision_column_name: str = 'class',\n",
    "    ):\n",
    "\n",
    "        # Primary Data Information\n",
    "        self.data = None\n",
    "        self.prepared_data = None\n",
    "        self.columns = None\n",
    "        self.continuous_columns = None\n",
    "        self.discrete_columns = None\n",
    "        self.scaled_data = None\n",
    "        self.decision_column_name = decision_column_name\n",
    "\n",
    "        # Secondary Data infromation\n",
    "        self.data_after_INI = None\n",
    "        self.silhouette_scores = None\n",
    "        self.lower_edge_value = {}\n",
    "        self.upper_edge_value = {}\n",
    "        self.outer_edge_value = {}\n",
    "        \n",
    "        # check_discrete\n",
    "        self.dis_check_threshold = 0.5\n",
    "        self.dis_checker = checker_type  # ratio\n",
    "        self.checker_top_n = 10  # defult number of top N for topN checker\n",
    "\n",
    "        # Config Tools\n",
    "        self.rst = None\n",
    "        self.encoder = LabelEncoder()\n",
    "        self.encoder_dict = dict()\n",
    "        self.scaler = StandardScaler()\n",
    "        self.natural_interval_model = 'kmeans'\n",
    "        self.NIM_message = 'Model for initiat the natural intervals cannot be blank'\n",
    "        self.comb_max_depth = comb_max_depth\n",
    "        self.all_combinations = None\n",
    "\n",
    "    def fit(\n",
    "            self,\n",
    "            x: pd.DataFrame,\n",
    "            continous_columns: list = [],\n",
    "            natural_interval_model: str = 'kmeans'\n",
    "    ):\n",
    "        \"\"\"Discretization using Rough Sets Theory (RST).\n",
    "\n",
    "        Fit `x` to an efficient intervals using the concept of RST \n",
    "        * asd\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : DataFrame\n",
    "            Full DataFrame (default is None)\n",
    "\n",
    "        continous_columns : list\n",
    "            Determind names of column(s) in the DataFarme as Continuous data. If `None` a function _check_continuous triger to determind names of column(s).\n",
    "\n",
    "        Raises\n",
    "        ------\n",
    "        NotMatchResult\n",
    "            If continous_columns `~None` model check the input with the checker determation if didn't match the result\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        # Reduct Data Intervals phase: Pre-process of discretization, intiate classification\n",
    "        # Pre-process of discretization\n",
    "        self.data = x\n",
    "        self.columns = self.data.columns\n",
    "        self.continuous_columns = continous_columns if continous_columns else self._check_continuous()\n",
    "        self.discrete_columns = list(set(self.columns).difference(self.continuous_columns))\n",
    "        self.discrete_columns.remove(self.decision_column_name)\n",
    "        self.scaled_data = self._scaling_continuous()\n",
    "        self.silhouette_scores = self._get_silhouette_score()\n",
    "\n",
    "        # Intiate classification\n",
    "        self.data_after_INI = getattr(self, '_%s_model' % natural_interval_model, lambda: self.NIM_message)()\n",
    "        self.all_combinations = self.get_combinations()\n",
    "        print(self.data_after_INI.nunique())\n",
    "\n",
    "        data = self.data.copy()  # local data vriable to save change in\n",
    "        data = self._labeling_discrete(data)\n",
    "        self.data_after_INI.columns = map((lambda x: x + '_AFTER'), self.data_after_INI.columns)\n",
    "\n",
    "        data = pd.concat([\n",
    "            data.reset_index(drop=True),\n",
    "            self.data_after_INI.reset_index(drop=True)\n",
    "        ], axis=1)\n",
    "\n",
    "        dependency_original_dict = {}\n",
    "        dependency_dict = {}\n",
    "        \n",
    "        # Duplicate Continuous columns\n",
    "        for continuous_att in self.continuous_columns:\n",
    "            att_AFTER = continuous_att + '_AFTER'\n",
    "            label_simulator = self.silhouette_scores[continuous_att]\n",
    "\n",
    "            self.prepared_data = data.copy()\n",
    "            self.prepared_data.sort_values([continuous_att], inplace=True, ignore_index=True)\n",
    "            temp_data = self.prepared_data.copy()\n",
    "            for n_label, o_label in enumerate(temp_data[att_AFTER].unique()):\n",
    "                indices_change_label = temp_data[temp_data[att_AFTER] == o_label].index.tolist()\n",
    "                self.prepared_data.loc[indices_change_label, (att_AFTER)] = n_label\n",
    "            self.prepared_data.sort_values([att_AFTER, continuous_att], inplace=True)\n",
    "\n",
    "            \n",
    "\n",
    "            value = 0\n",
    "            upper_flag = True\n",
    "            lower_flag = True\n",
    "            value_flag = True\n",
    "            value_sufx = ''\n",
    "\n",
    "            while value < label_simulator:\n",
    "                if value_flag:\n",
    "                    upper_flag = True\n",
    "                    lower_flag = True\n",
    "                    value_sufx = ''\n",
    "                indices = self.prepared_data[self.prepared_data[att_AFTER] == value].index.tolist()\n",
    "                if not len(indices) == 0:\n",
    "                    value_dict = '%s%s' % (value, value_sufx)\n",
    "                    if value not in dependency_dict.keys():\n",
    "                        dependency_dict.update({value_dict: {}})\n",
    "                        if upper_flag:\n",
    "                            dependency_dict[value_dict].update({\n",
    "                                'upper': {True: 0, False: 0}\n",
    "                            })\n",
    "\n",
    "                        if lower_flag:\n",
    "                            dependency_dict[value_dict].update({\n",
    "                                'lower': {True: 0, False: 0}\n",
    "                            })\n",
    "\n",
    "                    for combination in self.all_combinations:\n",
    "                        _combination = '|'.join(i for i in combination)\n",
    "                        _combination_AFTER = list(list(combination) + [att_AFTER])\n",
    "\n",
    "                        self.lower_data = self.prepared_data.copy()\n",
    "                        self.upper_data = self.prepared_data.copy()\n",
    "                        \n",
    "                        self.rst = RST(\n",
    "                            self.prepared_data,\n",
    "                            continuous_columns=self.continuous_columns,\n",
    "                            decision_column_name=self.decision_column_name,\n",
    "                            include_continuous_col=True\n",
    "                        )\n",
    "                        _, dependency = self.rst.get_dependency(combination=list(_combination_AFTER))\n",
    "                        dependency_original_dict.update({_combination: dependency})\n",
    "                        \n",
    "                        \n",
    "                        self._set_lower_edge_value(continuous_att, indices, value, label_simulator)\n",
    "                        self._set_upper_edge_value(continuous_att, indices, value, label_simulator)\n",
    "                        \n",
    "                        if value not in [0] and lower_flag:\n",
    "                            self.lower_data.loc[self.lower_edge_value[value]['idx'], (att_AFTER)] = value - 1\n",
    "                            self.rst = RST(\n",
    "                                self.lower_data,\n",
    "                                continuous_columns=self.continuous_columns,\n",
    "                                decision_column_name=self.decision_column_name,\n",
    "                                include_continuous_col=True\n",
    "                            )\n",
    "                            _, dependency = self.rst.get_dependency(\n",
    "                                combination=list(_combination_AFTER)\n",
    "                            )\n",
    "                            dependency_dict[value_dict]['lower'][dependency >= dependency_original_dict[_combination]] += 1\n",
    "                    \n",
    "                        if value not in [label_simulator - 1] and upper_flag:\n",
    "                            self.upper_data.loc[self.upper_edge_value[value]['idx'], (att_AFTER)] = value + 1\n",
    "                            self.rst = RST(\n",
    "                                self.upper_data,\n",
    "                                continuous_columns=self.continuous_columns,\n",
    "                                decision_column_name=self.decision_column_name,\n",
    "                                include_continuous_col=True\n",
    "                            )\n",
    "                            lower, dependency = self.rst.get_dependency(\n",
    "                                combination=list(_combination_AFTER)\n",
    "                            )\n",
    "                            dependency_dict[value_dict]['upper'][dependency >= dependency_original_dict[_combination]] += 1\n",
    "\n",
    "                    if lower_flag:\n",
    "                        is_lower = len(self.all_combinations)/1.5 <= dependency_dict[value_dict]['lower'][True]\n",
    "                    if upper_flag:\n",
    "                        is_upper = len(self.all_combinations)/1.5 <= dependency_dict[value_dict]['upper'][True]\n",
    "\n",
    "                    if is_lower or is_upper:\n",
    "                        lower_flag=is_lower\n",
    "                        upper_flag=is_upper\n",
    "                        value_flag=False\n",
    "                        value_sufx += '-'\n",
    "                        if is_lower:\n",
    "                            self.prepared_data.loc[self.lower_edge_value[value]['idx'], (att_AFTER)] = value - 1\n",
    "                            value_sufx += 'l'\n",
    "                        if is_upper:\n",
    "                            self.prepared_data.loc[self.upper_edge_value[value]['idx'], (att_AFTER)] = value + 1\n",
    "                            value_sufx += 'u'\n",
    "                    else:\n",
    "                        value += 1\n",
    "                        value_flag = True\n",
    "                else:\n",
    "                    value += 1\n",
    "                    value_flag = True\n",
    "\n",
    "        dependency_dict = collections.OrderedDict(sorted(dependency_dict.items()))       \n",
    "        with open('Steps.json', 'w+') as fp:\n",
    "            json.dump(dependency_dict, fp)\n",
    "            \n",
    "        self.prepared_data.to_csv('FinalData.csv')\n",
    "        data.to_csv('DataBeforeRST.csv')\n",
    "        return self.prepared_data\n",
    "\n",
    "    def _dbscan_model(self):\n",
    "        result = {}\n",
    "        for att in self.continuous_columns:\n",
    "            clustering = DBSCAN(eps=1, min_samples=5).fit(\n",
    "                self._np_array_reshaped(self.data[att])\n",
    "            )\n",
    "            result[att] = clustering.labels_\n",
    "        return pd.DataFrame(result)\n",
    "\n",
    "    def _kmeans_model(self):\n",
    "        result = {}\n",
    "        for att in self.continuous_columns:\n",
    "            clustering = KMeans(n_clusters=self.silhouette_scores[att], random_state=41).fit(\n",
    "                self._np_array_reshaped(self.scaled_data[att])\n",
    "            )\n",
    "            result[att] = clustering.labels_\n",
    "        return pd.DataFrame(result)\n",
    "\n",
    "    def _np_array_reshaped(self, data, reshape=(-1, 1)):\n",
    "        return np.array(data.tolist()).reshape(reshape[0], reshape[1])\n",
    "\n",
    "    def _check_continuous(self, continous_columns: list = []):\n",
    "        top_n = self.checker_top_n\n",
    "        likely = []\n",
    "\n",
    "        # check if attribute is continuous or discrete dataframe\n",
    "        for var in self.data.columns:\n",
    "            if self.dis_checker == 'topN':\n",
    "                # Check if the top n unique values account for more than a certain proportion of all values\n",
    "                if 1.*self.data[var].value_counts(normalize=True).head(top_n).sum() < 0.5:\n",
    "                    likely.append(var)\n",
    "            elif self.dis_checker == 'ratio':\n",
    "                # Find the ratio of number of unique values to the total number of unique values. Something like the following\n",
    "                if 1.*self.data[var].nunique()/self.data[var].count() > 0.5:\n",
    "                    likely.append(var)\n",
    "\n",
    "        common_names = ['id']\n",
    "\n",
    "        return [x for x in likely if x.lower() not in common_names]\n",
    "\n",
    "    def _labeling_discrete(self, data):\n",
    "\n",
    "        data_endocded = data.copy()\n",
    "\n",
    "        for col in data_endocded:\n",
    "            if col not in self.continuous_columns:\n",
    "                le = self.encoder.fit(data_endocded[col])\n",
    "                data_endocded[col] = self.encoder.transform(data_endocded[col])\n",
    "                self.encoder_dict[col] = self.encoder\n",
    "        return data_endocded\n",
    "\n",
    "    def _scaling_continuous(self):\n",
    "\n",
    "        data_cluster = self.data[self.continuous_columns].copy()\n",
    "        scaled_columns = self.scaler.fit_transform(data_cluster)\n",
    "        self.scaled_data = self.data.copy()\n",
    "        self.scaled_data[self.continuous_columns] = scaled_columns\n",
    "\n",
    "        return self.scaled_data\n",
    "\n",
    "    def _get_silhouette_score(self):\n",
    "        scores = {}\n",
    "        for att in self.continuous_columns:\n",
    "            temp_score = []\n",
    "            scores[att] = 3\n",
    "            for n_clusters in range(3, 9):\n",
    "                # Initialize the clusterer with n_clusters value and a random generator\n",
    "                # seed of 10 for reproducibility.\n",
    "                clusterer = KMeans(n_clusters=n_clusters, random_state=10)\n",
    "                cluster_labels = clusterer.fit_predict(\n",
    "                    self._np_array_reshaped(self.scaled_data[att]))\n",
    "\n",
    "                # The silhouette_score gives the average value for all the samples.\n",
    "                # This gives a perspective into the density and separation of the formed\n",
    "                # clusters\n",
    "                silhouette_avg = silhouette_score(\n",
    "                    self._np_array_reshaped(self.scaled_data[att]), cluster_labels)\n",
    "                temp_score.append(silhouette_avg)\n",
    "            scores[att] = temp_score.index(max(temp_score)) + 3\n",
    "        return scores\n",
    "\n",
    "    def get_combinations(self, comb_max_depth: int = None):\n",
    "        if not comb_max_depth:\n",
    "            comb_max_depth = self.comb_max_depth\n",
    "        combX = []\n",
    "        for idx, _ in enumerate(self.discrete_columns):\n",
    "            if comb_max_depth and comb_max_depth == idx:\n",
    "                break\n",
    "            combX.extend(list(combinations(self.discrete_columns, idx + 1)))\n",
    "\n",
    "        return sorted(combX, key=len)\n",
    "    \n",
    "    def _set_lower_edge_value(self, att, indices, value, s_c):\n",
    "        same_value = self.prepared_data.loc[indices][att].values.tolist()\n",
    "        lower_same_value = self.prepared_data[att].isin([same_value[0]])\n",
    "        lower_temp = self.prepared_data[lower_same_value]\n",
    "        self.lower_edge_value.update({\n",
    "            value: {\n",
    "                'idx': lower_temp.index.tolist(),\n",
    "                'value': lower_temp.values.tolist()[0][0],\n",
    "            }\n",
    "        })\n",
    "\n",
    "        return self.lower_edge_value\n",
    "\n",
    "    def _set_upper_edge_value(self, att, indices, value, s_c):\n",
    "        same_value = self.prepared_data.loc[indices][att].values.tolist()\n",
    "        upper_same_value = self.prepared_data[att].isin([same_value[-1]])\n",
    "        upper_temp = self.prepared_data[upper_same_value]\n",
    "        self.upper_edge_value.update({\n",
    "            value: {\n",
    "                'idx': upper_temp.index.tolist(),\n",
    "                'value': upper_temp.values.tolist()[0][0],\n",
    "            }\n",
    "        })\n",
    "\n",
    "        return self.upper_edge_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annual_Premium    3\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Driving_License</th>\n",
       "      <th>Region_Code</th>\n",
       "      <th>Previously_Insured</th>\n",
       "      <th>Vehicle_Age</th>\n",
       "      <th>Vehicle_Damage</th>\n",
       "      <th>Annual_Premium</th>\n",
       "      <th>Policy_Sales_Channel</th>\n",
       "      <th>Response</th>\n",
       "      <th>Annual_Premium_AFTER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2630.0</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2630.0</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2630.0</td>\n",
       "      <td>79</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2630.0</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2630.0</td>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>101215.0</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113379.0</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>115719.0</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>127772.0</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>251853.0</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Gender  Driving_License  Region_Code  Previously_Insured  Vehicle_Age  \\\n",
       "0          0                1            3                   1            1   \n",
       "1          1                1           40                   0            0   \n",
       "2          1                1            6                   0            0   \n",
       "3          1                1           15                   0            1   \n",
       "4          0                1           28                   0            2   \n",
       "...      ...              ...          ...                 ...          ...   \n",
       "4995       1                1            8                   1            1   \n",
       "4996       1                1            8                   1            1   \n",
       "4997       0                1           28                   0            1   \n",
       "4998       1                1           28                   0            0   \n",
       "4999       0                1           28                   0            0   \n",
       "\n",
       "      Vehicle_Damage  Annual_Premium  Policy_Sales_Channel  Response  \\\n",
       "0                  0          2630.0                    70         0   \n",
       "1                  1          2630.0                    22         1   \n",
       "2                  1          2630.0                    79         1   \n",
       "3                  0          2630.0                    70         0   \n",
       "4                  1          2630.0                    75         0   \n",
       "...              ...             ...                   ...       ...   \n",
       "4995               0        101215.0                    70         0   \n",
       "4996               0        113379.0                    70         0   \n",
       "4997               0        115719.0                    70         0   \n",
       "4998               1        127772.0                    19         1   \n",
       "4999               1        251853.0                    17         1   \n",
       "\n",
       "      Annual_Premium_AFTER  \n",
       "0                        0  \n",
       "1                        0  \n",
       "2                        0  \n",
       "3                        0  \n",
       "4                        0  \n",
       "...                    ...  \n",
       "4995                     2  \n",
       "4996                     2  \n",
       "4997                     2  \n",
       "4998                     2  \n",
       "4999                     2  \n",
       "\n",
       "[5000 rows x 10 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = pd.read_csv('datasets/d1_bootstraped.csv')\n",
    "\n",
    "# Uncomment for creating a new sample of the datasets with bootstrap\n",
    "# freq = pd.DataFrame({'Response':['0', '1'], 'nostoextract':[46710, 46710], })\n",
    "# data = bootstrap(data,freq)\n",
    "\n",
    "df = data.copy()\n",
    "df = df.sample(5000, random_state=41) # 41\n",
    "df['Response'].value_counts().plot(kind='bar')\n",
    "df.drop(['Vintage', 'Age'], axis=1, inplace=True)\n",
    "df.nunique()\n",
    "\n",
    "drst = DRST(comb_max_depth=1, decision_column_name='Response')\n",
    "drst_fit = drst.fit(df, continous_columns=['Annual_Premium'])\n",
    "drst_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "temperature    6\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>outlook</th>\n",
       "      <th>temperature</th>\n",
       "      <th>wind</th>\n",
       "      <th>class</th>\n",
       "      <th>temperature_AFTER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>65</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>69</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>71</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>72</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>75</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>81</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>83</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2</td>\n",
       "      <td>85</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    outlook  temperature  wind  class  temperature_AFTER\n",
       "0         0           64     0      1                  0\n",
       "1         1           65     0      0                  0\n",
       "2         1           68     1      1                  0\n",
       "3         2           69     1      1                  0\n",
       "4         1           70     1      1                  0\n",
       "5         1           71     0      0                  1\n",
       "6         2           72     1      0                  2\n",
       "7         0           72     0      1                  2\n",
       "8         1           75     1      1                  3\n",
       "9         2           75     0      1                  3\n",
       "10        2           80     0      0                  4\n",
       "11        0           81     1      1                  4\n",
       "12        0           83     1      1                  4\n",
       "13        2           85     1      0                  4"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tennis = pd.read_csv('play-tennis.csv')\n",
    "drst = DRST(comb_max_depth=2, decision_column_name='class')\n",
    "drst_fit = drst.fit(tennis, continous_columns=['temperature'])\n",
    "drst_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.3 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e99f971b6d48a9f8afab1d34758ddbb9a87e8265f2671e414e3fdd21b2f0ea4e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
