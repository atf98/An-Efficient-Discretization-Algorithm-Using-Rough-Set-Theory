{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import tree, metrics \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "from model.DRST import DRST\n",
    "\n",
    "# https://github.com/tatsumiw/ChiMerge/blob/master/ChiMerge.py\n",
    "# https://www.aaai.org/Papers/AAAI/1992/AAAI92-019.pdf\n",
    "from model.Algorithms.ChiMerge import ChiMerge\n",
    "\n",
    "# https://github.com/MengChiehLiu/Entropy-Based-Binning/blob/main/entropy.ipynb\n",
    "from model.Algorithms.EntropyBasedBinning import cal_entropy, get_bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_dir = os.getcwd()\n",
    "disc_datasets = {}\n",
    "test_ration = {'20-80': [20, 80], '30-70': [30, 70], '40-60': [40, 60]}\n",
    "\n",
    "data = pd.read_csv('datasets/health_insurance.csv')\n",
    "data = data.sample(1000, random_state=41) # 41 # 600 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_c_c = ['Annual_Premium']\n",
    "def encoder(d):\n",
    "    le = LabelEncoder()\n",
    "    encoder_dict = dict()\n",
    "    data_endocded = d.copy()\n",
    "\n",
    "    for col in data_endocded:\n",
    "        if col not in ex_c_c:\n",
    "            le = le.fit(data_endocded[col])\n",
    "            data_endocded[col] = le.transform(data_endocded[col])\n",
    "            encoder_dict[col] = le\n",
    "    return data_endocded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annual_Premium    3\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "drst_test_data = data.copy()\n",
    "\n",
    "drst = DRST(comb_max_depth=3, decision_column_name='Response', save_output=False)\n",
    "drst_fit, continuous_columns = drst.fit(drst_test_data, continous_columns=['Annual_Premium'])\n",
    "drst_fit.drop(continuous_columns, axis=1, inplace=True)\n",
    "disc_datasets.update({\n",
    "    'drst': encoder(drst_fit)\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bins result: 0.0 23595.0 27284.0 27707.0\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "chi_test_data = data.copy()\n",
    "# chi_test_data.drop(continuous_columns, axis=1, inplace=True)\n",
    "\n",
    "chi_test_bins = ChiMerge(chi_test_data[['Annual_Premium', 'Response']], 'Annual_Premium', 'Response', confidenceVal=1.4, bin=4, sample=None)\n",
    "chi_test_bins = chi_test_bins.interval.values.tolist()\n",
    "\n",
    "chi_test_data['Annual_Premium'] = np.digitize(chi_test_data['Annual_Premium'], chi_test_bins)\n",
    "\n",
    "print(\"bins result: %s\" % ' '.join(str(i) for i in chi_test_bins))\n",
    "print(len(chi_test_bins))\n",
    "disc_datasets.update({\n",
    "    'chi': encoder(chi_test_data)\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bins result: 0 34388.0 34489.0 34813.0 127772.0\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "ent_test_data = data.copy()\n",
    "# ent_test_data.drop(continuous_columns, axis=1, inplace=True)\n",
    "\n",
    "part_LeafNodes, part_entropy_list, LeafNodes, entropy_list = cal_entropy(ent_test_data, 'Annual_Premium', 'Response')\n",
    "ent_test_bins = get_bin(part_LeafNodes)[1]\n",
    "\n",
    "ent_test_data['Annual_Premium'] = np.digitize(ent_test_data['Annual_Premium'], ent_test_bins)\n",
    "\n",
    "print(\"bins result: %s\" % ' '.join(str(i) for i in ent_test_bins))\n",
    "print(len(ent_test_bins))\n",
    "disc_datasets.update({\n",
    "    'ent': encoder(ent_test_data)\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Test_RFC(test_split='20-80', print_flag=False):\n",
    "    '''\n",
    "        test_split is the percentage of the splitting for the data, which train_split =  100 - test_split\n",
    "    '''\n",
    "    for name, dataset in disc_datasets.items():\n",
    "        # Scraping info of dataset from datasets variable\n",
    "        data = dataset.copy()\n",
    "        class_name = 'Response'\n",
    "        regex_name = name\n",
    "\n",
    "        \n",
    "        file = open('%s\\\\output\\\\compare\\\\accuracy_result.txt' % (current_dir), 'a+')\n",
    "        \n",
    "        Path('%s\\\\output\\\\compare\\\\RandomForestClassifier\\\\%s' % (current_dir, test_split)).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        feature_names = [i for i in data.columns if i != class_name]\n",
    "        X, y = data[feature_names], data[class_name]\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = test_ration[test_split][0]/100, random_state=0)\n",
    "        # clf = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "        clf = RandomForestClassifier(n_estimators = 100, random_state=21) \n",
    "        \n",
    "        # Training the model on the training dataset\n",
    "        # fit function is used to train the model using the training sets as parameters\n",
    "        clf.fit(X_train, y_train)\n",
    "        \n",
    "        # performing predictions on the test dataset\n",
    "        y_pred = clf.predict(X_test)\n",
    "        \n",
    "        # metrics are used to find accuracy or error\n",
    "        report = classification_report(y_test, y_pred, output_dict=True)\n",
    "        report.update({'Rules Number': len(tree.export_text(clf.estimators_[0]))})\n",
    "        report_df = pd.DataFrame(report).transpose()\n",
    "        report_df.to_csv('%s\\\\output\\\\compare\\\\RandomForestClassifier\\\\%s\\\\report-CLFTester-%s-%s.csv' % (current_dir, test_split, regex_name, name))\n",
    "        file.write(\"ACCURACY for data %s in model RandomForestClassifier with split ration %s === %s\\n\" % (name, test_split,metrics.accuracy_score(y_test, y_pred)))\n",
    "        if print_flag:\n",
    "            # using metrics module for accuracy calculation\n",
    "            print('------------------------')\n",
    "            print(name)\n",
    "            print('------------------------')\n",
    "            print(\"Number of rules Extracted from the model: %s\" % len(tree.export_text(clf.estimators_[0])))\n",
    "            print(\"ACCURACY: %s\" % (metrics.accuracy_score(y_test, y_pred)))\n",
    "            print(\"CLASSIFICATION REPORT \\n %s\" % report)\n",
    "\n",
    "        tree.plot_tree(clf.estimators_[0],\n",
    "                    feature_names = feature_names, \n",
    "                    class_names=class_name,\n",
    "                    filled = True)\n",
    "        plt.savefig('%s\\\\output\\\\compare\\\\RandomForestClassifier\\\\%s\\\\CLFTester-%s-%s.png' % (current_dir, test_split, regex_name, name))\n",
    "        plt.close()\n",
    "    file.write('\\n')\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path('%s\\\\output\\\\compare' % (current_dir)).mkdir()\n",
    "Path('%s\\\\output\\\\compare\\\\accuracy_result.txt' % (current_dir)).touch(exist_ok=True)\n",
    "file = open('%s\\\\output\\\\compare\\\\accuracy_result.txt' % (current_dir), 'a+')\n",
    "file.write('___________________________________________________\\n')\n",
    "file.write('All RandomForestClassifier Results\\n')\n",
    "file.write('___________________________________________________\\n')\n",
    "file.close()\n",
    "for tp in test_ration.keys():\n",
    "    # Health Insurance Data Tester\n",
    "    Test_RFC(test_split=tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.3 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e99f971b6d48a9f8afab1d34758ddbb9a87e8265f2671e414e3fdd21b2f0ea4e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
