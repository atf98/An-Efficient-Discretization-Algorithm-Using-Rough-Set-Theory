{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tooldev import RST\n",
    "from tooldev.sample import bootstrap\n",
    "\n",
    "from itertools import combinations\n",
    "\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import collections\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "from sklearn.cluster import DBSCAN, KMeans\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, OneHotEncoder\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.neighbors import KernelDensity\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "class Error(Exception):\n",
    "    \"\"\"Base class for other exceptions\"\"\"\n",
    "    pass\n",
    "\n",
    "\n",
    "class NotMatchResult(Error):\n",
    "    \"\"\"Raised when the input value is too small\"\"\"\n",
    "    pass\n",
    "\n",
    "\n",
    "class DRST:\n",
    "    '''\n",
    "        An Efficient Discretization Algorithm Using Rough Set Theory\n",
    "\n",
    "        ...\n",
    "\n",
    "        Attributes\n",
    "        ----------\n",
    "        checker_type : str='topN'\n",
    "            Type of the checker of data to determind wether data column is Continous or Discrete\n",
    "\n",
    "        Methods\n",
    "        -------\n",
    "        fit(x: DataFrame, continous_columns: list)\n",
    "\n",
    "        Note\n",
    "        -------\n",
    "\n",
    "        Example\n",
    "        -------\n",
    "\n",
    "\n",
    "    '''\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        comb_max_depth: int = None,\n",
    "        decision_column_name: str = 'class',\n",
    "        output_loction=None,\n",
    "        save_output=True,\n",
    "        checker_type: str = 'topN',\n",
    "        topN_thrshold: str = 0.5,\n",
    "        ratio_thrshold: str = 0.5,\n",
    "    ):\n",
    "\n",
    "        # Primary Data Information\n",
    "        self.data = None\n",
    "        self.prepared_data = None\n",
    "        self.columns = None\n",
    "        self.continuous_columns = None\n",
    "        self.discrete_columns = None\n",
    "        self.scaled_data = None\n",
    "        self.decision_column_name = decision_column_name\n",
    "\n",
    "        # Secondary Data infromation\n",
    "        self.data_after_INI = None\n",
    "        self.silhouette_scores = None\n",
    "        self.lower_edge_value = {}\n",
    "        self.upper_edge_value = {}\n",
    "        self.outer_edge_value = {}\n",
    "        \n",
    "        # check_discrete\n",
    "        self.dis_check_threshold = 0.5\n",
    "        self.dis_checker = checker_type  # ratio\n",
    "        self.topN_thrshold = topN_thrshold  # topN_thrshold\n",
    "        self.ratio_thrshold = ratio_thrshold  # ratio_thrshold\n",
    "        self.checker_top_n = 10  # defult number of top N for topN checker\n",
    "\n",
    "        # Config Tools\n",
    "        self.rst = None\n",
    "        self.encoder = LabelEncoder()\n",
    "        self.encoder_dict = dict()\n",
    "        self.scaler = StandardScaler()\n",
    "        self.natural_interval_model = 'kmeans'\n",
    "        self.NIM_message = 'Model for initiat the natural intervals cannot be blank'\n",
    "        self.comb_max_depth = comb_max_depth\n",
    "        self.all_combinations = None\n",
    "        \n",
    "        self.output_loction = os.getcwd() if not output_loction else os.getcwd() + '\\\\' + output_loction\n",
    "        self.save_output = save_output\n",
    "\n",
    "    def fit(\n",
    "            self,\n",
    "            x: pd.DataFrame,\n",
    "            continous_columns: list = [],\n",
    "            natural_interval_model: str = 'kmeans',\n",
    "            ensamble_threshold: int = 0.9\n",
    "    ):\n",
    "        \"\"\"Discretization using Rough Sets Theory (RST).\n",
    "\n",
    "        Fit `x` to an efficient intervals using the concept of RST \n",
    "        * asd\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : DataFrame\n",
    "            Full DataFrame (default is None)\n",
    "\n",
    "        continous_columns : list\n",
    "            Determind names of column(s) in the DataFarme as Continuous data. If `None` a function _check_continuous triger to determind names of column(s).\n",
    "\n",
    "        Raises\n",
    "        ------\n",
    "        NotMatchResult\n",
    "            If continous_columns `~None` model check the input with the checker determation if didn't match the result\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        # Reduct Data Intervals phase: Pre-process of discretization, intiate classification\n",
    "        # Pre-process of discretization\n",
    "        self.ensamble_theshold = ensamble_threshold\n",
    "        self.data = x\n",
    "        self.columns = self.data.columns\n",
    "        self.continuous_columns = continous_columns if continous_columns else self._check_continuous()\n",
    "        self.discrete_columns = list(set(self.columns).difference(self.continuous_columns))\n",
    "        self.discrete_columns.remove(self.decision_column_name)\n",
    "        self.scaled_data = self._scaling_continuous()\n",
    "        self.silhouette_scores = self._get_silhouette_score()\n",
    "\n",
    "        # Intiate classification\n",
    "        self.data_after_INI = getattr(self, '_%s_model' % natural_interval_model, lambda: self.NIM_message)()\n",
    "        self.all_combinations = self.get_combinations()\n",
    "        print(self.data_after_INI.nunique())\n",
    "\n",
    "        data = self.data.copy()  # local data vriable to save change in\n",
    "        data = self._labeling_discrete(data)\n",
    "        self.data_after_INI.columns = map((lambda x: x + '_AFTER'), self.data_after_INI.columns)\n",
    "\n",
    "        data = pd.concat([\n",
    "            data.reset_index(drop=True),\n",
    "            self.data_after_INI.reset_index(drop=True)\n",
    "        ], axis=1)\n",
    "\n",
    "        dependency_original_dict = {}\n",
    "        dependency_dict = {}\n",
    "        \n",
    "        # Duplicate Continuous columns\n",
    "        for continuous_att in self.continuous_columns:\n",
    "            att_AFTER = continuous_att + '_AFTER'\n",
    "            label_simulator = self.silhouette_scores[continuous_att]\n",
    "\n",
    "            self.prepared_data = data.copy()\n",
    "            self.prepared_data.sort_values([continuous_att], inplace=True, ignore_index=True)\n",
    "            temp_data = self.prepared_data.copy()\n",
    "            for n_label, o_label in enumerate(temp_data[att_AFTER].unique()):\n",
    "                indices_change_label = temp_data[temp_data[att_AFTER] == o_label].index.tolist()\n",
    "                self.prepared_data.loc[indices_change_label, (att_AFTER)] = n_label\n",
    "            self.prepared_data.sort_values([att_AFTER, continuous_att], inplace=True)\n",
    "\n",
    "            \n",
    "\n",
    "            value = 0\n",
    "            upper_flag = True\n",
    "            lower_flag = True\n",
    "            value_flag = True\n",
    "            value_sufx = ''\n",
    "\n",
    "            while value < label_simulator:\n",
    "                if value_flag:\n",
    "                    upper_flag = True\n",
    "                    lower_flag = True\n",
    "                    value_sufx = ''\n",
    "                indices = self.prepared_data[self.prepared_data[att_AFTER] == value].index.tolist()\n",
    "                if not len(indices) == 0:\n",
    "                    value_dict = '%s%s' % (value, value_sufx)\n",
    "                    if value not in dependency_dict.keys():\n",
    "                        dependency_dict.update({value_dict: {}})\n",
    "                        if upper_flag:\n",
    "                            dependency_dict[value_dict].update({\n",
    "                                'upper': {True: 0, False: 0}\n",
    "                            })\n",
    "\n",
    "                        if lower_flag:\n",
    "                            dependency_dict[value_dict].update({\n",
    "                                'lower': {True: 0, False: 0}\n",
    "                            })\n",
    "\n",
    "                    for combination in self.all_combinations:\n",
    "                        _combination = '|'.join(i for i in combination)\n",
    "                        _combination_AFTER = list(list(combination) + [att_AFTER])\n",
    "\n",
    "                        self.lower_data = self.prepared_data.copy()\n",
    "                        self.upper_data = self.prepared_data.copy()\n",
    "                        \n",
    "                        self.rst = RST(\n",
    "                            self.prepared_data,\n",
    "                            continuous_columns=self.continuous_columns,\n",
    "                            decision_column_name=self.decision_column_name,\n",
    "                            include_continuous_col=True\n",
    "                        )\n",
    "                        _, dependency = self.rst.get_dependency(combination=list(_combination_AFTER))\n",
    "                        dependency_original_dict.update({_combination: dependency})\n",
    "                        \n",
    "                        \n",
    "                        self._set_lower_edge_value(continuous_att, indices, value, label_simulator)\n",
    "                        self._set_upper_edge_value(continuous_att, indices, value, label_simulator)\n",
    "                        \n",
    "                        if value not in [0] and lower_flag:\n",
    "                            self.lower_data.loc[self.lower_edge_value[value]['idx'], (att_AFTER)] = value - 1\n",
    "                            self.rst = RST(\n",
    "                                self.lower_data,\n",
    "                                continuous_columns=self.continuous_columns,\n",
    "                                decision_column_name=self.decision_column_name,\n",
    "                                include_continuous_col=True\n",
    "                            )\n",
    "                            _, dependency = self.rst.get_dependency(\n",
    "                                combination=list(_combination_AFTER)\n",
    "                            )\n",
    "                            dependency_dict[value_dict]['lower'][dependency >= dependency_original_dict[_combination]] += 1\n",
    "                    \n",
    "                        if value not in [label_simulator - 1] and upper_flag:\n",
    "                            self.upper_data.loc[self.upper_edge_value[value]['idx'], (att_AFTER)] = value + 1\n",
    "                            self.rst = RST(\n",
    "                                self.upper_data,\n",
    "                                continuous_columns=self.continuous_columns,\n",
    "                                decision_column_name=self.decision_column_name,\n",
    "                                include_continuous_col=True\n",
    "                            )\n",
    "                            lower, dependency = self.rst.get_dependency(\n",
    "                                combination=list(_combination_AFTER)\n",
    "                            )\n",
    "                            dependency_dict[value_dict]['upper'][dependency >= dependency_original_dict[_combination]] += 1\n",
    "\n",
    "                    if lower_flag:\n",
    "                        is_lower = len(self.all_combinations)*self.ensamble_theshold <= dependency_dict[value_dict]['lower'][True]\n",
    "                    if upper_flag:\n",
    "                        is_upper = len(self.all_combinations)*self.ensamble_theshold <= dependency_dict[value_dict]['upper'][True]\n",
    "\n",
    "                    if is_lower or is_upper:\n",
    "                        lower_flag=is_lower\n",
    "                        upper_flag=is_upper\n",
    "                        value_flag=False\n",
    "                        value_sufx += '-'\n",
    "                        if is_lower:\n",
    "                            self.prepared_data.loc[self.lower_edge_value[value]['idx'], (att_AFTER)] = value - 1\n",
    "                            value_sufx += 'l'\n",
    "                        if is_upper:\n",
    "                            self.prepared_data.loc[self.upper_edge_value[value]['idx'], (att_AFTER)] = value + 1\n",
    "                            value_sufx += 'u'\n",
    "                    else:\n",
    "                        value += 1\n",
    "                        value_flag = True\n",
    "                else:\n",
    "                    value += 1\n",
    "                    value_flag = True\n",
    "\n",
    "        dependency_dict = collections.OrderedDict(sorted(dependency_dict.items()))\n",
    "        if self.save_output:\n",
    "            Path(self.output_loction + '\\\\_log').mkdir(parents=True, exist_ok=True)\n",
    "            with open(self.output_loction + '\\\\_log\\\\logMap.json', 'w+') as fp:\n",
    "                json.dump(dependency_dict, fp)\n",
    "                \n",
    "            self.prepared_data.to_csv(self.output_loction + '\\\\DataAfterDRST.csv')\n",
    "            data.to_csv(self.output_loction + '\\\\DataBeforeDRST.csv')\n",
    "        return [self.prepared_data, self.continuous_columns]\n",
    "\n",
    "    def _dbscan_model(self):\n",
    "        result = {}\n",
    "        for att in self.continuous_columns:\n",
    "            clustering = DBSCAN(eps=1, min_samples=5).fit(\n",
    "                self._np_array_reshaped(self.data[att])\n",
    "            )\n",
    "            result[att] = clustering.labels_\n",
    "        return pd.DataFrame(result)\n",
    "\n",
    "    def _kmeans_model(self):\n",
    "        result = {}\n",
    "        for att in self.continuous_columns:\n",
    "            clustering = KMeans(n_clusters=self.silhouette_scores[att], random_state=41).fit(\n",
    "                self._np_array_reshaped(self.scaled_data[att])\n",
    "            )\n",
    "            result[att] = clustering.labels_\n",
    "        return pd.DataFrame(result)\n",
    "\n",
    "    def _np_array_reshaped(self, data, reshape=(-1, 1)):\n",
    "        return np.array(data.tolist()).reshape(reshape[0], reshape[1])\n",
    "\n",
    "    def _check_continuous(self, continous_columns: list = []):\n",
    "        top_n = self.checker_top_n\n",
    "        likely = []\n",
    "        # check if attribute is continuous or discrete dataframe\n",
    "        for var in self.data.columns:\n",
    "            if self.data[var].dtype in [np.int64, np.float64]:\n",
    "                if self.dis_checker == 'topN':\n",
    "                    # Check if the top n unique values account for more than a certain proportion of all values\n",
    "                    if 1.*self.data[var].value_counts(normalize=True).head(top_n).sum() < self.topN_thrshold:\n",
    "                        likely.append(var)\n",
    "                elif self.dis_checker == 'ratio':\n",
    "                    # Find the ratio of number of unique values to the total number of unique values. Something like the following\n",
    "                    if 1.*self.data[var].nunique()/self.data[var].count() > self.ratio_thrshold:\n",
    "                        likely.append(var)\n",
    "\n",
    "        common_names = ['id']\n",
    "\n",
    "        return [x for x in likely if x.lower() not in common_names]\n",
    "\n",
    "    def _labeling_discrete(self, data):\n",
    "\n",
    "        data_endocded = data.copy()\n",
    "\n",
    "        for col in data_endocded:\n",
    "            if col not in self.continuous_columns:\n",
    "                le = self.encoder.fit(data_endocded[col])\n",
    "                data_endocded[col] = self.encoder.transform(data_endocded[col])\n",
    "                self.encoder_dict[col] = self.encoder\n",
    "        return data_endocded\n",
    "\n",
    "    def _scaling_continuous(self):\n",
    "        print(self.continuous_columns)\n",
    "        data_cluster = self.data[self.continuous_columns].copy()\n",
    "        scaled_columns = self.scaler.fit_transform(data_cluster)\n",
    "        self.scaled_data = self.data.copy()\n",
    "        self.scaled_data[self.continuous_columns] = scaled_columns\n",
    "\n",
    "        return self.scaled_data\n",
    "\n",
    "    def _get_silhouette_score(self):\n",
    "        scores = {}\n",
    "        for att in self.continuous_columns:\n",
    "            temp_score = []\n",
    "            scores[att] = 3\n",
    "            for n_clusters in range(3, 9):\n",
    "                # Initialize the clusterer with n_clusters value and a random generator\n",
    "                # seed of 10 for reproducibility.\n",
    "                clusterer = KMeans(n_clusters=n_clusters, random_state=10)\n",
    "                cluster_labels = clusterer.fit_predict(\n",
    "                    self._np_array_reshaped(self.scaled_data[att]))\n",
    "\n",
    "                # The silhouette_score gives the average value for all the samples.\n",
    "                # This gives a perspective into the density and separation of the formed\n",
    "                # clusters\n",
    "                silhouette_avg = silhouette_score(\n",
    "                    self._np_array_reshaped(self.scaled_data[att]), cluster_labels)\n",
    "                temp_score.append(silhouette_avg)\n",
    "            scores[att] = temp_score.index(max(temp_score)) + 3\n",
    "        return scores\n",
    "\n",
    "    def get_combinations(self, comb_max_depth: int = None):\n",
    "        if not comb_max_depth:\n",
    "            comb_max_depth = self.comb_max_depth\n",
    "        combX = []\n",
    "        for idx, _ in enumerate(self.discrete_columns):\n",
    "            if comb_max_depth and comb_max_depth == idx:\n",
    "                break\n",
    "            combX.extend(list(combinations(self.discrete_columns, idx + 1)))\n",
    "\n",
    "        return sorted(combX, key=len)\n",
    "    \n",
    "    def _set_lower_edge_value(self, att, indices, value, s_c):\n",
    "        same_value = self.prepared_data.loc[indices][att].values.tolist()\n",
    "        lower_same_value = self.prepared_data[att].isin([same_value[0]])\n",
    "        lower_temp = self.prepared_data[lower_same_value]\n",
    "        self.lower_edge_value.update({\n",
    "            value: {\n",
    "                'idx': lower_temp.index.tolist(),\n",
    "                'value': lower_temp.values.tolist()[0][0],\n",
    "            }\n",
    "        })\n",
    "\n",
    "        return self.lower_edge_value\n",
    "\n",
    "    def _set_upper_edge_value(self, att, indices, value, s_c):\n",
    "        same_value = self.prepared_data.loc[indices][att].values.tolist()\n",
    "        upper_same_value = self.prepared_data[att].isin([same_value[-1]])\n",
    "        upper_temp = self.prepared_data[upper_same_value]\n",
    "        self.upper_edge_value.update({\n",
    "            value: {\n",
    "                'idx': upper_temp.index.tolist(),\n",
    "                'value': upper_temp.values.tolist()[0][0],\n",
    "            }\n",
    "        })\n",
    "\n",
    "        return self.upper_edge_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7542</th>\n",
       "      <td>Male</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt; 1 Year</td>\n",
       "      <td>No</td>\n",
       "      <td>29654</td>\n",
       "      <td>152</td>\n",
       "      <td>115</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7716</th>\n",
       "      <td>Female</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt; 1 Year</td>\n",
       "      <td>No</td>\n",
       "      <td>33054</td>\n",
       "      <td>152</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89071</th>\n",
       "      <td>Male</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>&gt; 2 Years</td>\n",
       "      <td>Yes</td>\n",
       "      <td>69040</td>\n",
       "      <td>122</td>\n",
       "      <td>245</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71895</th>\n",
       "      <td>Female</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>1-2 Year</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2630</td>\n",
       "      <td>26</td>\n",
       "      <td>164</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1979</th>\n",
       "      <td>Male</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt; 1 Year</td>\n",
       "      <td>No</td>\n",
       "      <td>22147</td>\n",
       "      <td>152</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>977</th>\n",
       "      <td>Male</td>\n",
       "      <td>65</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>1-2 Year</td>\n",
       "      <td>No</td>\n",
       "      <td>29016</td>\n",
       "      <td>120</td>\n",
       "      <td>235</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93013</th>\n",
       "      <td>Male</td>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1-2 Year</td>\n",
       "      <td>Yes</td>\n",
       "      <td>48250</td>\n",
       "      <td>26</td>\n",
       "      <td>114</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25612</th>\n",
       "      <td>Male</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt; 1 Year</td>\n",
       "      <td>No</td>\n",
       "      <td>32108</td>\n",
       "      <td>26</td>\n",
       "      <td>192</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65735</th>\n",
       "      <td>Male</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt; 1 Year</td>\n",
       "      <td>Yes</td>\n",
       "      <td>51296</td>\n",
       "      <td>124</td>\n",
       "      <td>230</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81662</th>\n",
       "      <td>Male</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt; 1 Year</td>\n",
       "      <td>Yes</td>\n",
       "      <td>25506</td>\n",
       "      <td>26</td>\n",
       "      <td>182</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0   1  2   3  4          5    6      7    8    9  10\n",
       "7542     Male  24  1  45  1   < 1 Year   No  29654  152  115   0\n",
       "7716   Female  33  1  32  1   < 1 Year   No  33054  152   36   0\n",
       "89071    Male  53  1  28  0  > 2 Years  Yes  69040  122  245   1\n",
       "71895  Female  40  1  28  0   1-2 Year  Yes   2630   26  164   1\n",
       "1979     Male  25  1  29  1   < 1 Year   No  22147  152   43   0\n",
       "...       ...  .. ..  .. ..        ...  ...    ...  ...  ...  ..\n",
       "977      Male  65  1  41  1   1-2 Year   No  29016  120  235   0\n",
       "93013    Male  52  1   8  0   1-2 Year  Yes  48250   26  114   1\n",
       "25612    Male  30  1  41  1   < 1 Year   No  32108   26  192   0\n",
       "65735    Male  22  1  28  0   < 1 Year  Yes  51296  124  230   1\n",
       "81662    Male  32  1  33  0   < 1 Year  Yes  25506   26  182   1\n",
       "\n",
       "[1000 rows x 11 columns]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('datasets/health_insurance.csv', header=None)\n",
    "data = data.sample(1000, random_state=41) # 41\n",
    "data = data.replace('?', np.NaN)\n",
    "data.dropna(thresh=(data.shape[0] * .93), axis=1, inplace=True)\n",
    "data.dropna(thresh=(data.shape[1] * .93), axis=0, inplace=True)\n",
    "data.fillna(data.mode().iloc[0], inplace=True)\n",
    "data.columns = [str(c) for c in data.columns]\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1', '3', '7', '9']\n",
      "1    3\n",
      "3    8\n",
      "7    3\n",
      "9    3\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>2</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>8</th>\n",
       "      <th>10</th>\n",
       "      <th>1_AFTER</th>\n",
       "      <th>3_AFTER</th>\n",
       "      <th>7_AFTER</th>\n",
       "      <th>9_AFTER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0  2  4  5  6   8  10  1_AFTER  3_AFTER  7_AFTER  9_AFTER\n",
       "0    0  1  1  1  0  35   0        1        3        0        0\n",
       "1    0  1  0  2  1  15   1        2        3        2        0\n",
       "2    0  1  0  0  1  29   0        2        6        0        0\n",
       "3    0  1  1  0  0  28   0        2        3        0        0\n",
       "4    0  1  0  1  1  42   0        1        7        0        0\n",
       "..  .. .. .. .. ..  ..  ..      ...      ...      ...      ...\n",
       "995  1  1  0  1  1  35   0        1        3        0        2\n",
       "996  1  1  0  1  1  35   1        1        4        0        2\n",
       "997  1  1  0  1  1  39   1        1        3        1        2\n",
       "998  0  1  0  2  1  15   0        0        6        0        2\n",
       "999  1  1  0  0  1  29   1        0        3        2        2\n",
       "\n",
       "[1000 rows x 11 columns]"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drst = DRST(comb_max_depth=1, decision_column_name=data.columns[-1], topN_thrshold=.7, save_output=False)\n",
    "drst_fit, continuous_columns = drst.fit(data, ensamble_threshold=0.9)\n",
    "drst_fit.drop(continuous_columns, axis=1, inplace=True)\n",
    "drst_fit"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.3 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e99f971b6d48a9f8afab1d34758ddbb9a87e8265f2671e414e3fdd21b2f0ea4e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
